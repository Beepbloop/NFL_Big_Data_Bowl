{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom kaggle.competitions import nflrush\nfrom string import punctuation\nfrom tqdm import tqdm\nimport gc, re\nimport pickle\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split, KFold\n\nimport lightgbm as lgb\nfrom catboost import Pool, CatBoostRegressor\n\nfrom keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda,BatchNormalization, LeakyReLU\nfrom keras.models import Sequential\nimport keras.backend as K\nfrom keras.callbacks import Callback,EarlyStopping,ModelCheckpoint\nfrom  keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.losses import binary_crossentropy\nfrom keras.utils import to_categorical\n\nimport codecs\nimport time\nimport datetime\nimport re\n\nTRAIN_OFFLINE = False\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 150)","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"/kaggle/input/nfl-big-data-bowl-2020/train.csv\n/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/sample_submission.csv.encrypted\n/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/competition.cpython-36m-x86_64-linux-gnu.so\n/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/test.csv.encrypted\n/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/__init__.py\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%%time\ntrain_df_org = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)","execution_count":2,"outputs":[{"output_type":"stream","text":"CPU times: user 6.44 s, sys: 1.3 s, total: 7.74 s\nWall time: 7.68 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df_org.copy()","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_player_specific_cols(col_names):\n    cols, total_players = [], 22\n    for col in col_names:\n        for player in range(total_players):\n            cols.append(f'{col}_player{player}')\n    return cols\ndef mean_without_overflow_fast(col):\n    col /= len(col)\n    return col.mean() * len(col)\ndef encode_cyclic_feature(df, col, max_vals):\n    df[col + '_sin'] = np.sin(2 * np.pi * df[col]/max_vals)\n    df[col + '_cos'] = np.cos(2 * np.pi * df[col]/max_vals)\n    del df[col]\n    return df\ndef extract_timestamp(df, timestamp_col):\n    df[f'{timestamp_col}Hour'] = np.uint8(df[timestamp_col].dt.hour)\n    df[f'{timestamp_col}Minute'] = np.uint8(df[timestamp_col].dt.minute)\n    df[f'{timestamp_col}Second'] = np.uint8(df[timestamp_col].dt.second)\n    return df\ndef get_player_specific_cols(col_names):\n    cols, total_players = [], 22\n    for col in col_names:\n        for player in range(total_players):\n            cols.append(f'{col}_player{player}')\n    return cols\ndef height_to_inches(player_height):\n    return int(player_height.split('-')[0]) * 12 + int(player_height.split('-')[1])\ndef bdate_to_age(bdate):\n    now = pd.to_datetime('now')\n    return (now.year - bdate.dt.year) - ((now.month - bdate.dt.month) < 0)\ndef get_grouping_dict(df, key):\n    dicts = []\n    for _, row in df.iterrows():\n        dicts.append(dict([(pos.split()[1], pos.split()[0]) for (pos) in row[key].split(',')]))\n    return dicts","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef groupby_playid(df, is_training=True):\n    \n    total_players = 22\n    non_player_features = ['GameId', 'PlayId', 'Season', 'YardLine', 'Quarter', 'GameClock',\n       'PossessionTeam', 'Down', 'Distance', 'FieldPosition',\n       'HomeScoreBeforePlay', 'VisitorScoreBeforePlay',\n       'OffenseFormation', 'OffensePersonnel', 'DefendersInTheBox',\n       'DefensePersonnel', 'PlayDirection', 'TimeHandoff', 'TimeSnap',\n       'Yards', 'HomeTeamAbbr', 'VisitorTeamAbbr', 'Week', 'Stadium',\n       'Location', 'StadiumType', 'Turf', 'GameWeather', 'Temperature',\n       'Humidity', 'WindSpeed', 'WindDirection', 'NflId']\n    \n    if not is_training:\n        non_player_features.remove('Yards')\n    \n    df['X_speed'] = np.cos(df['Dir'])*df['S']\n    df['Y_speed'] = np.sin(df['Dir'])*df['S']\n    \n    player_features = ['Team', 'X', 'Y', 'S', 'A', 'Dis', 'Orientation', 'Dir','X_speed', \n                       'Y_speed', 'DisplayName', 'JerseyNumber', 'PlayerHeight', 'PlayerWeight',\n                       'PlayerBirthDate', 'PlayerCollegeName', 'Position', 'NflIdRusher']\n    \n    playids_groups = df.groupby('PlayId').size().keys()\n    \n    player_features_columns = []\n    for feature in player_features:\n        for player in range(total_players):\n            player_features_columns.append(f'{feature}_player{player}')\n    \n    # first assign non_player features which are common for a single game playid\n    final_df = pd.DataFrame()\n    final_df[non_player_features] = df.groupby('PlayId')[non_player_features].first().reset_index(drop=True)\n    final_df = final_df.reindex(final_df.columns.tolist() + player_features_columns, axis=1)\n    temp_cols = []\n    if is_training:\n        for group in tqdm(playids_groups, position=0, leave=True):\n            temp_cols.append(df[df['PlayId'] == group][player_features].melt()['value'])\n    else:\n        for group in playids_groups:\n            temp_cols.append(df[df['PlayId'] == group][player_features].melt()['value'])\n    final_df[player_features_columns] = pd.DataFrame(temp_cols).values\n    \n    return final_df","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_engineering(df, is_training=True, label_encoders={}):\n    \n    if is_training:\n        label_encoders['NflId'] = LabelEncoder()\n        label_encoders['NflId'].fit(df['NflId'])\n    try:\n        df['NflId'] = label_encoders['NflId'].transform(df['NflId'])\n    except:\n        df['NflId'] = np.nan\n       \n    team_dict = {\n        'away': 0,\n        'home': 1\n    }\n    df['Team'] = df['Team'].map(team_dict)\n    season_dict = {\n        2017: 0,\n        2018: 1\n    }\n    df['Season'] = df['Season'].map(season_dict)\n    df = groupby_playid(df, is_training)\n    \n    df = df.drop(['Season', 'Temperature', 'Humidity'], axis = 1)\n    \n    if is_training:\n        df = df.apply(lambda group: group.interpolate(limit_direction='both'))\n    \n    df['WindDirection'] = df['WindDirection'].fillna(method='backfill')\n    df['WindSpeed'] = df['WindSpeed'].fillna(method='backfill')\n    df['GameWeather'] = df['GameWeather'].fillna(method='backfill')\n    df['StadiumType'] = df['StadiumType'].fillna(method='backfill')\n    df['FieldPosition'] = df['FieldPosition'].fillna(method='backfill')\n    df['OffenseFormation'] = df['OffenseFormation'].fillna(method='backfill')\n    \n    df['GameClock'] = pd.to_datetime(df['GameClock'])\n    df['TimeHandoff'] = pd.to_datetime(df['TimeHandoff'])\n    df['TimeSnap'] = pd.to_datetime(df['TimeSnap'])\n    \n    df = extract_timestamp(df, 'GameClock')\n    df = extract_timestamp(df, 'TimeHandoff')\n    df = extract_timestamp(df, 'TimeSnap')\n    df = df.drop(['GameClock', 'TimeHandoff', 'TimeSnap'], axis=1)\n    \n    df = encode_cyclic_feature(df, 'GameClockHour', 24)\n    df = encode_cyclic_feature(df, 'GameClockMinute', 60)\n    df = encode_cyclic_feature(df, 'GameClockSecond', 60)\n    \n    df = encode_cyclic_feature(df, 'TimeHandoffHour', 24)\n    df = encode_cyclic_feature(df, 'TimeHandoffMinute', 60)\n    df = encode_cyclic_feature(df, 'TimeHandoffSecond', 60)\n    \n    df = encode_cyclic_feature(df, 'TimeSnapHour', 24)\n    df = encode_cyclic_feature(df, 'TimeSnapMinute', 60)\n    df = encode_cyclic_feature(df, 'TimeSnapSecond', 60)\n    \n    def transform_game_weather(x):\n        x = str(x).lower()\n        if 'indoor' in x:\n            return  'indoor'\n        elif 'cloud' in x or 'coudy' in x or 'clouidy' in x:\n            return 'cloudy'\n        elif 'rain' in x or 'shower' in x:\n            return 'rain'\n        elif 'sunny' in x:\n            return 'sunny'\n        elif 'clear' in x:\n            return 'clear'\n        elif 'cold' in x or 'cool' in x:\n            return 'cool'\n        elif 'snow' in x:\n            return 'snow'\n        return x\n    \n    df['GameWeather'] = df['GameWeather'].apply(lambda row: transform_game_weather(row))\n    \n    categorical_features = ['PossessionTeam', 'FieldPosition', 'OffenseFormation', 'PlayDirection', 'HomeTeamAbbr', \n                        'VisitorTeamAbbr', 'NflId','Stadium', 'Location', 'GameWeather'] + get_player_specific_cols(['Position', 'PlayerCollegeName', 'NflIdRusher'])\n    \n    for col in get_player_specific_cols(['PlayerHeight']):\n        df[col] = df[col].apply(lambda x: height_to_inches(x))\n    \n    for col in get_player_specific_cols(['PlayerBirthDate']):\n        df[col] = pd.to_datetime(df[col])\n        df[col] = bdate_to_age(df[col])\n    \n    for cat in categorical_features:\n        if is_training:\n            label_encoders[cat] = LabelEncoder()\n            label_encoders[cat].fit(df[cat])\n        try:\n            df[cat] = label_encoders[cat].transform(df[cat])\n        except Exception as e:\n            df[cat] = np.nan # Put NaN in case when any unseen label is found in testing dataset.\n            \n        \n#     offense_groups = ['QB', 'RB', 'OL', 'FB', 'WR', 'TE']\n#     defense_groups = ['DL', 'LB', 'CB', 'S']\n    \n#     offense_dicts = get_grouping_dict(df, 'OffensePersonnel')\n#     defense_dicts = get_grouping_dict(df, 'DefensePersonnel')\n    \n#     offense_grps_df = pd.DataFrame(offense_dicts).rename(columns={'OL': 'OL_offense', 'DL': 'DL_offense', 'LB': 'LB_offense', 'DB': 'DB_offense'}).fillna(0).astype(int)\n#     defense_grps_df = pd.DataFrame(defense_dicts).rename(columns={'OL': 'OL_defense', 'DL': 'DL_defense', 'LB': 'LB_defense', 'DB': 'DB_defense'}).fillna(0).astype(int)\n    \n#     df = pd.concat([df, offense_grps_df, defense_grps_df], axis=1)\n    df = df.drop(['OffensePersonnel', 'DefensePersonnel'], axis=1)\n    \n    try:\n        df['NflIdRusher'] = label_encoders['NflId'].transform(df['NflIdRusher'])\n    except:\n        df['NflIdRusher'] = np.nan\n        \n    wind_directions = ['N', 'E', 'S', 'W', 'NE', 'SE', 'SW', 'NW', 'NNE', 'ENE', 'ESE', 'SSE', 'SSW', 'WSW', 'WNW', 'NNW']  # https://www.quora.com/What-is-the-definition-of-SSW-wind-direction\n    \n    df.loc[df['WindSpeed'].isin(wind_directions), 'WindSpeed'] = np.nan\n    df.loc[~df['WindDirection'].isin(wind_directions), 'WindDirection'] = np.nan\n    \n    df['WindDirection'] = df['WindDirection'].fillna(method='backfill')\n    df['WindSpeed'] = df['WindSpeed'].fillna(method='backfill')\n    \n    if is_training:\n        label_encoders['WindDirection'] = LabelEncoder()\n        label_encoders['WindDirection'].fit(df['WindDirection'])\n    try:\n        df['WindDirection'] = label_encoders['WindDirection'].transform(df['WindDirection'])\n    except Exception as e:\n        df['WindDirection'] = np.nan\n    \n    def transform_windspeed(speed):\n        speed = str(speed)\n        if 'MPH' in speed or 'mph' in speed or 'MPh' in speed:\n            speed = speed.replace('MPH', '').strip()\n            speed = speed.replace('MPH', '').strip()\n            speed = speed.replace('MPh', '').strip()\n        if '-' in speed:\n            return (float(speed.split('-')[0]) + float(speed.split('-')[1]))/2\n        try:\n            return float(speed)\n        except:\n            return 10 # https://sciencing.com/average-daily-wind-speed-24011.html\n        \n    df['WindSpeed'] = df['WindSpeed'].apply(lambda speed: transform_windspeed(speed))\n    \n    beaufort = [(0, 0, 0.3), (1, 0.3, 1.6), (2, 1.6, 3.4), (3, 3.4, 5.5), (4, 5.5, 8), \n                (5, 8, 10.8), (6, 10.8, 13.9), (7, 13.9, 17.2), (8, 17.2, 20.8), \n                (9, 20.8, 24.5), (10, 24.5, 28.5), (11, 28.5, 33), (12, 33, 200)]\n\n    for item in beaufort:\n        df.loc[(df['WindSpeed']>=item[1]) & (df['WindSpeed']<item[2]), 'beaufort_scale'] = item[0]\n    \n    df['DefendersInTheBox_vs_Distance'] = df['DefendersInTheBox'] / df['Distance']\n    df['Field_eq_Possession'] = df['FieldPosition'] == df['PossessionTeam']\n    \n    # Add BMI as a feature: formula for BMI: kg/m^2\n    total_players = 22\n    \n    def get_bmi(height, weight):\n        return weight / (height ** 2) * 755\n    \n    def is_rusher(x, y):\n        return x == y\n    \n    for player in range(total_players):\n        df[f'BMI_player{player}'] = np.vectorize(get_bmi)(df[f'PlayerHeight_player{player}'], df[f'PlayerWeight_player{player}'])\n        df[f'is_rusher_player{player}'] = np.vectorize(is_rusher)(df['NflId'], df[f'NflIdRusher_player{player}'])\n\n    # Cleaning the Turf to Natural and artificial\n    # from https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112681#latest-649087\n    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', \n            'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', \n            'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', \n            'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', \n            'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n\n    df['Turf'] = df['Turf'].map(Turf)\n    df['Turf'] = df['Turf'] == 'Natural'\n    \n    def clean_StadiumType(txt):\n        if pd.isna(txt):\n            return np.nan\n        txt = txt.lower()\n        txt = ''.join([c for c in txt if c not in punctuation])\n        txt = re.sub(' +', ' ', txt)\n        txt = txt.strip()\n        txt = txt.replace('outside', 'outdoor')\n        txt = txt.replace('outdor', 'outdoor')\n        txt = txt.replace('outddors', 'outdoor')\n        txt = txt.replace('outdoors', 'outdoor')\n        txt = txt.replace('oudoor', 'outdoor')\n        txt = txt.replace('indoors', 'indoor')\n        txt = txt.replace('ourdoor', 'outdoor')\n        txt = txt.replace('retractable', 'rtr.')\n        return txt\n        \n    df['StadiumType'] = df['StadiumType'].apply(clean_StadiumType)\n    \n    def transform_StadiumType(txt):\n        if pd.isna(txt):\n            return np.nan\n        if 'outdoor' in txt or 'open' in txt:\n            return 1\n        if 'indoor' in txt or 'closed' in txt:\n            return 0\n\n        return np.nan\n    \n    df['StadiumType'] = df['StadiumType'].apply(transform_StadiumType)\n    \n    # from https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112173#latest-647309\n#     df['JerseyNumberGrouped'] = df['JerseyNumber'] // 10\n    \n    if is_training:\n        return df, label_encoders\n    return df","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def processData(df, isTrain=True):\n    non_feature_cols = ['GameId', 'PlayId'] + get_player_specific_cols(['DisplayName', 'JerseyNumber','NflIdRusher'])\n    target_col = ['Yards']\n    if (isTrain):\n        df, label_encoders = feature_engineering(df)\n        \n        X_train = df.drop(non_feature_cols+target_col, axis=1)\n        X_train = X_train.drop(['NflId','StadiumType','NflIdRusher','Team_player0','Team_player1','Team_player2','Team_player3','Team_player4','Team_player5','Team_player6','Team_player7','Team_player8','Team_player9','Team_player10','Team_player11','Team_player12','Team_player13','Team_player14','Team_player15','Team_player16','Team_player17','Team_player18','Team_player19','Team_player20','Team_player21'],axis=1)\n        X = X_train.copy().to_numpy()\n#         X = X_train.copy()\n        \n        Y_train = df[target_col]\n        yards = Y_train.to_numpy().flatten()\n        y = np.zeros((yards.shape[0], 199))\n        for idx, target in enumerate(yards):\n            y[idx][99 + target] = 1\n        return X,y\n    else: \n        df = feature_engineering(df,False)\n        X_test = df.drop(non_feature_cols, axis=1)\n        X_test = X_test.drop(['NflId','StadiumType','NflIdRusher','Team_player0','Team_player1','Team_player2','Team_player3','Team_player4','Team_player5','Team_player6','Team_player7','Team_player8','Team_player9','Team_player10','Team_player11','Team_player12','Team_player13','Team_player14','Team_player15','Team_player16','Team_player17','Team_player18','Team_player19','Team_player20','Team_player21'],axis=1)\n#         X_test = X_test.drop(['Location'],axis=1)\n        X = X_test.to_numpy()\n#         return X_test\n        return X\n    \n","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nX,y = processData(train_df)","execution_count":null,"outputs":[{"output_type":"stream","text":"  0%|          | 16/23171 [00:00<02:28, 155.61it/s]","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda\nfrom keras.models import Model\nimport keras.backend as K\nimport re\nfrom keras.losses import binary_crossentropy\nfrom  keras.callbacks import EarlyStopping,ModelCheckpoint\nimport codecs\n\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\nfrom sklearn.metrics import f1_score\n\n\n\n\nclass CRPSCallback(Callback):\n    \n    def __init__(self,validation, predict_batch_size=20, include_on_batch=False):\n        super(CRPSCallback, self).__init__()\n        self.validation = validation\n        self.predict_batch_size = predict_batch_size\n        self.include_on_batch = include_on_batch\n        \n        print('validation shape',len(self.validation))\n\n    def on_batch_begin(self, batch, logs={}):\n        pass\n\n    def on_train_begin(self, logs={}):\n        if not ('CRPS_score_val' in self.params['metrics']):\n            self.params['metrics'].append('CRPS_score_val')\n\n    def on_batch_end(self, batch, logs={}):\n        if (self.include_on_batch):\n            logs['CRPS_score_val'] = float('-inf')\n\n    def on_epoch_end(self, epoch, logs={}):\n        logs['CRPS_score_val'] = float('-inf')\n            \n        if (self.validation):\n            X_valid, y_valid = self.validation[0], self.validation[1]\n            y_pred = self.model.predict(X_valid)\n            y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n            y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n            val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n            val_s = np.round(val_s, 6)\n            logs['CRPS_score_val'] = val_s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.losses import categorical_crossentropy\ndef get_model(x_tr,y_tr,x_val,y_val):\n    IN_DIM = x_tr.shape[1]\n    model = Sequential()\n    model.add(Dense(1024,input_dim = IN_DIM))\n    model.add(LeakyReLU(alpha=0.3))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(1024))\n    model.add(LeakyReLU(alpha=0.3))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(512))\n    model.add(LeakyReLU(alpha=0.3))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(512))\n    model.add(LeakyReLU(alpha=0.3))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(256))\n    model.add(LeakyReLU(alpha=0.3))\n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    \n    model.add(Dense(199, activation='softmax'))\n#     print(model.summary())\n    \n#     loss = categorical_crossentropy()\n    model.compile(optimizer='adam', loss=categorical_crossentropy,metrics=[])\n    #add lookahead\n#     lookahead = Lookahead(k=5, alpha=0.5) # Initialize Lookahead\n#     lookahead.inject(model) # add into model\n\n    \n    es = EarlyStopping(monitor='CRPS_score_val', \n                       mode='min',\n                       restore_best_weights=True, \n                       verbose=1, \n                       patience=2)\n\n    mc = ModelCheckpoint('best_model.h5',monitor='CRPS_score_val',mode='min',\n                                   save_best_only=True, verbose=1, save_weights_only=True)\n    \n    bsz = 1024\n    steps = x_tr.shape[0]/bsz\n    model.fit(x_tr,y_tr,callbacks=[CRPSCallback(validation = (x_val,y_val)),es,mc], epochs=1000, batch_size=bsz)\n#     model.load_weights(\"best_model.h5\")\n    \n    y_pred = model.predict(x_val)\n    y_valid = y_val\n    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * x_val.shape[0])\n    crps = np.round(val_s, 6)\n\n    return model,crps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nimport time\n\nlosses = []\nmodels = []\ncrps_csv = []\n\ns_time = time.time()\n\n\nfor k in range(2):\n    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(X)):\n        print(\"-----------\")\n        print(\"-----------\")\n        tr_x,tr_y = X[tr_inds],y[tr_inds]\n        val_x,val_y = X[val_inds],y[val_inds]\n        model,crps = get_model(tr_x,tr_y,val_x,val_y)\n        models.append(model)\n        print(\"the %d fold crps is %f\"%((k_fold+1),crps))\n        crps_csv.append(crps)\n \n# print(\"mean crps is %f\"%np.mean(crps_csv))\n\n\ndef predict(x_te):\n    model_num = len(models)\n    for k,m in enumerate(models):\n        if k==0:\n            y_pred = m.predict(x_te,batch_size=1024)\n        else:\n            y_pred+=m.predict(x_te,batch_size=1024)\n            \n    y_pred = y_pred / model_num\n    \n    return y_pred        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"mean crps is %f\"%np.mean(crps_csv))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom kaggle.competitions import nflrush\nenv = nflrush.make_env()\niter_test = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evl = []\ni = 0\nfor (test_df, sample_prediction_df) in iter_test:\n    print(test_df)\n    basetable = processData(test_df,False)\n#         basetable = create_features(test_df, deploy=True)\n#         basetable.drop(['GameId','PlayId'], axis=1, inplace=True)\n    print(basetable.shape)\n    scaled_basetable = scaler.transform(basetable)\n    print(basetable)\n\n    y_pred = predict(scaled_basetable)\n#         y_pred = predict(basetable)\n    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1).tolist()[0]\n\n    preds_df = pd.DataFrame(data=[y_pred], columns=sample_prediction_df.columns)\n    env.predict(preds_df)\n\nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,col in enumerate(processData(test_df,False).columns.to_list()):\n    print(\"test:\",col)\n    print(\"train:\",X.columns.to_list()[i])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processData(test_df,False).isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prd = processData(test_df,False)\n# print(basetable.shape)\n# scaled_basetable = scaler.transform(basetable)\n# print(basetable)\n# predict()\n\nbasetable = processData(test_df,False)\n\n# print(basetable.shape)\nscaled_basetable = scaler.transform(basetable)\n# print(basetable)\n\n# y_pred = predict(scaled_basetable)\n# y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1).tolist()[0]\n\n# preds_df = pd.DataFrame(data=[y_pred], columns=sample_prediction_df.columns)\n# preds_df\nbasetable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_prediction_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evluate"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom kaggle.competitions import nflrush\nenv = nflrush.make_env()\niter_test = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (test_df, sample_prediction_df) in iter_test:\n    basetable = processData(test_df,False)\n#         basetable = create_features(test_df, deploy=True)\n#         basetable.drop(['GameId','PlayId'], axis=1, inplace=True)\n    print(basetable.shape)\n    scaled_basetable = scaler.transform(basetable)\n    print(basetable)\n\n    y_pred = predict(scaled_basetable)\n#         y_pred = predict(basetable)\n    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1).tolist()[0]\n\n    preds_df = pd.DataFrame(data=[y_pred], columns=sample_prediction_df.columns)\n    env.predict(preds_df)\n\nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}