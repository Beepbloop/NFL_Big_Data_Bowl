{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:27:34.444922Z",
     "start_time": "2019-11-06T13:27:30.768021Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "TRAIN_ABLE_FALSE=True\n",
    "if TRAIN_ABLE_FALSE:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mtr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda,BatchNormalization\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from  keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import datetime\n",
    "\n",
    "TRAIN_OFFLINE = True\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPClusterI(data):\n",
    "    return (1.0*np.tanh(((np.where(((data[:,24]) * 2.0) > -998, ((data[:,24]) + (((((data[:,24]) + (data[:,6]))) * 2.0))), data[:,24] )) - (((((data[:,25]) - (((((((data[:,24]) * 2.0)) + (data[:,9]))) * 2.0)))) * 2.0)))) +\n",
    "            1.0*np.tanh(((((((((data[:,10]) + (((data[:,24]) - (data[:,25]))))) + (data[:,24]))) + (((data[:,28]) + (((data[:,1]) + (data[:,24]))))))) + (((((data[:,24]) + (((((data[:,10]) - (data[:,19]))) + (data[:,9]))))) + (((data[:,24]) * 2.0)))))) +\n",
    "            1.0*np.tanh(((((((((data[:,2]) + (((data[:,2]) - (data[:,16]))))) + (((((((((data[:,8]) - (((((data[:,16]) - (data[:,2]))) - (data[:,2]))))) + (data[:,1]))) + (((data[:,13]) - (data[:,16]))))) - (data[:,18]))))) + (data[:,28]))) * 2.0)) +\n",
    "            1.0*np.tanh(((((((((((data[:,9]) + (((data[:,28]) + (data[:,24]))))) - (data[:,22]))) + (((((data[:,24]) + (data[:,9]))) + (data[:,1]))))) + (((((((data[:,10]) + (data[:,24]))) + (data[:,24]))) - (data[:,19]))))) * 2.0)) +\n",
    "            1.0*np.tanh(((((((((((data[:,23]) + (((data[:,9]) + (((data[:,23]) - (data[:,25]))))))) + (((data[:,24]) * 2.0)))) + (data[:,28]))) + (((data[:,8]) - (((data[:,24]) - (((data[:,24]) + (data[:,13]))))))))) + (((data[:,24]) - (data[:,20]))))) +\n",
    "            1.0*np.tanh((((-1.0*((data[:,18])))) + (((((data[:,24]) + (((((data[:,9]) + (((data[:,23]) + (data[:,24]))))) - ((-1.0*((np.tanh((((np.where(data[:,28] > -998, data[:,6], data[:,6] )) * 2.0))))))))))) * 2.0)))) +\n",
    "            1.0*np.tanh(((data[:,28]) + (((((((((((((data[:,24]) - (data[:,22]))) - (data[:,25]))) + (((((data[:,24]) + (data[:,13]))) - (((data[:,19]) - (data[:,9]))))))) + (((data[:,24]) + (data[:,13]))))) + (data[:,8]))) - (data[:,19]))))) +\n",
    "            1.0*np.tanh(((np.tanh((((np.tanh((((data[:,6]) + (data[:,5]))))) + (data[:,23]))))) + (((np.where(data[:,6] < -998, data[:,24], ((((((((np.tanh((np.tanh((data[:,5]))))) + (data[:,24]))) * 2.0)) * 2.0)) + (((data[:,19]) * (data[:,24])))) )) + (data[:,6]))))) +\n",
    "            1.0*np.tanh(((data[:,8]) + ((((((((((data[:,18]) - (data[:,28]))) + (data[:,24]))/2.0)) * (data[:,22]))) + (((((((data[:,13]) - ((((data[:,22]) + (((data[:,18]) - (data[:,28]))))/2.0)))) + (data[:,24]))) * 2.0)))))) +\n",
    "            1.0*np.tanh(((((data[:,24]) + (((np.where(data[:,13] < -998, data[:,24], data[:,1] )) + (((data[:,4]) + (((((((data[:,24]) * 2.0)) + (data[:,10]))) + ((-1.0*((((data[:,13]) * 2.0))))))))))))) + (((data[:,24]) + (data[:,1]))))) +\n",
    "            1.0*np.tanh(((((((((((data[:,9]) * (data[:,24]))) + (((data[:,3]) * (data[:,24]))))) + (((data[:,28]) + (((((data[:,13]) * (data[:,24]))) + (((data[:,20]) * (data[:,24]))))))))) * 2.0)) + (((((data[:,24]) * (data[:,24]))) + (data[:,9]))))) +\n",
    "            1.0*np.tanh(((((data[:,28]) - (((data[:,20]) * (data[:,5]))))) + (((((data[:,24]) * (((((data[:,4]) + (data[:,3]))) + (((((((data[:,13]) + (data[:,20]))) + ((-1.0*((data[:,15])))))) * 2.0)))))) + (data[:,4]))))) +\n",
    "            1.0*np.tanh((((((-1.0*((((data[:,15]) * (((((data[:,20]) * (data[:,24]))) + (((data[:,6]) - (((data[:,15]) * (data[:,24])))))))))))) + (((data[:,6]) - (data[:,25]))))) - (((data[:,16]) * (((data[:,22]) + (data[:,4]))))))) +\n",
    "            1.0*np.tanh((((((((data[:,24]) + (data[:,2]))/2.0)) + (((data[:,9]) + (data[:,13]))))) + (((((data[:,24]) + (((data[:,24]) * (np.tanh(((((((data[:,20]) + (data[:,9]))/2.0)) + (((data[:,13]) / 2.0)))))))))) * (((data[:,5]) + (data[:,20]))))))) +\n",
    "            1.0*np.tanh(((((((data[:,13]) * (np.where((-1.0*((data[:,15]))) > -998, data[:,10], data[:,15] )))) - (((((data[:,24]) * (data[:,15]))) * 2.0)))) - ((-1.0*((((((-1.0*((data[:,27])))) + (((data[:,24]) * ((((data[:,27]) + (((data[:,13]) * (data[:,6]))))/2.0)))))/2.0))))))) +\n",
    "            1.0*np.tanh(((((((((((data[:,4]) + (data[:,25]))) + (((data[:,3]) * (data[:,3]))))) + (((data[:,24]) + (((data[:,24]) + (((data[:,27]) + (data[:,8]))))))))) * (data[:,24]))) + (((((data[:,27]) + (data[:,25]))) * (data[:,8]))))) +\n",
    "            1.0*np.tanh(((data[:,24]) * ((((data[:,13]) + ((((-1.0*((data[:,1])))) + (((((data[:,3]) + (data[:,6]))) + (((((((((data[:,24]) * (((data[:,6]) + (data[:,2]))))) * 2.0)) + (data[:,3]))) + (((data[:,20]) + ((-1.0*((data[:,1])))))))))))))/2.0)))) +\n",
    "            1.0*np.tanh((-1.0*((((((((((((((((data[:,24]) + (np.where(data[:,2] < -998, data[:,24], data[:,3] )))/2.0)) + (((data[:,13]) + (((data[:,24]) * 2.0)))))/2.0)) + (data[:,2]))/2.0)) + (data[:,0]))/2.0)) * (((data[:,15]) * (((data[:,28]) + (((((data[:,24]) * 2.0)) * 2.0))))))))))) +\n",
    "            1.0*np.tanh(np.where(data[:,20] > -998, ((data[:,16]) * (((((((((data[:,3]) + ((((data[:,13]) + (data[:,20]))/2.0)))) + ((((data[:,8]) + (data[:,24]))/2.0)))) + (data[:,28]))) * (((data[:,15]) - (np.tanh((data[:,8])))))))), (((data[:,9]) + (data[:,28]))/2.0) )) +\n",
    "            1.0*np.tanh((((((((((((data[:,3]) * (((data[:,3]) * (((data[:,3]) * ((-1.0*((data[:,24])))))))))) + (data[:,25]))) + (data[:,25]))/2.0)) + ((-1.0*((((data[:,9]) * 2.0))))))) * (np.where(data[:,9] > -998, data[:,15], data[:,3] )))) +\n",
    "            1.0*np.tanh((((((data[:,0]) + (data[:,9]))/2.0)) * (((((((data[:,24]) * (data[:,3]))) * (data[:,3]))) - (np.where(data[:,3] > -998, (((data[:,28]) + ((((data[:,1]) + (data[:,24]))/2.0)))/2.0), ((((data[:,24]) * (data[:,3]))) * (data[:,1])) )))))) +\n",
    "            1.0*np.tanh(((((data[:,3]) * (((((((data[:,3]) * (data[:,16]))) * (data[:,16]))) * (np.where(np.where((((data[:,3]) + (data[:,16]))/2.0) < -998, data[:,1], data[:,16] ) < -998, data[:,1], data[:,16] )))))) * (data[:,1]))) +\n",
    "            1.0*np.tanh((((np.where(((((((data[:,1]) - (data[:,3]))) - (data[:,18]))) - (data[:,17])) < -998, data[:,3], ((((data[:,27]) + (data[:,18]))) * (data[:,9])) )) + (((data[:,16]) * (((((data[:,1]) - (data[:,3]))) - (((data[:,27]) + (data[:,18]))))))))/2.0)) +\n",
    "            1.0*np.tanh(((np.where((((data[:,22]) + (data[:,22]))/2.0) < -998, data[:,8], data[:,19] )) * ((((((((((data[:,22]) + (data[:,1]))/2.0)) * (data[:,22]))) - (((((((data[:,13]) + (data[:,20]))/2.0)) + (data[:,22]))/2.0)))) - ((((data[:,8]) + (((data[:,13]) + (data[:,3]))))/2.0)))))) +\n",
    "            1.0*np.tanh(((data[:,24]) * ((((((data[:,3]) * ((((data[:,3]) + (((data[:,3]) * (((data[:,3]) * (data[:,0]))))))/2.0)))) + (np.where((1.90717267990112305) > -998, (((-1.0*(((1.90717267990112305))))) - (((data[:,3]) * 2.0))), data[:,3] )))/2.0)))) +\n",
    "            1.0*np.tanh(((data[:,2]) - (np.where(data[:,13] < -998, (-1.0*((data[:,13]))), np.where(data[:,5] > -998, ((data[:,1]) - (((((((data[:,15]) + (((data[:,5]) * ((-1.0*((data[:,0])))))))/2.0)) + (((data[:,13]) * (data[:,5]))))/2.0))), data[:,13] ) )))) +\n",
    "            1.0*np.tanh(((((((-1.0*((((data[:,19]) - (((((data[:,21]) + (((data[:,1]) * (((((((data[:,2]) - (data[:,4]))) - (data[:,24]))) + (data[:,19]))))))) + (data[:,2])))))))) + ((-1.0*(((((((data[:,2]) + (data[:,21]))/2.0)) - (data[:,2])))))))/2.0)) / 2.0)) +\n",
    "            1.0*np.tanh((((((((data[:,3]) - (data[:,1]))) + (data[:,13]))/2.0)) * ((((((data[:,28]) + ((-1.0*((np.where(((((data[:,24]) - (data[:,1]))) - (data[:,24])) > -998, data[:,2], data[:,28] ))))))) + (data[:,24]))/2.0)))) +\n",
    "            1.0*np.tanh((-1.0*((((((data[:,16]) - (data[:,6]))) - (((np.tanh((((np.tanh(((-1.0*((np.where(data[:,16] < -998, data[:,16], ((data[:,9]) - (((((data[:,16]) - (data[:,6]))) - (((data[:,28]) - (data[:,16])))))) ))))))) * 2.0)))) * 2.0))))))) +\n",
    "            1.0*np.tanh(((data[:,27]) * (((((((data[:,16]) + (data[:,27]))/2.0)) + (((((data[:,27]) * (((((((((np.where(data[:,7] < -998, ((data[:,27]) / 2.0), data[:,2] )) + (data[:,1]))/2.0)) - (((data[:,27]) / 2.0)))) + (data[:,7]))/2.0)))) * (data[:,27]))))/2.0)))) +\n",
    "            1.0*np.tanh(((((data[:,1]) - (data[:,22]))) * ((-1.0*(((((((data[:,1]) * (data[:,10]))) + (np.where(data[:,22] < -998, (((data[:,22]) + (data[:,1]))/2.0), (((((((((data[:,22]) + (data[:,1]))/2.0)) + (data[:,1]))/2.0)) + ((-1.0*((np.tanh((np.tanh((data[:,19])))))))))/2.0) )))/2.0))))))) +\n",
    "            1.0*np.tanh(np.where(data[:,1] < -998, ((np.tanh(((((((data[:,1]) + (data[:,25]))/2.0)) * (data[:,25]))))) - (data[:,1])), ((data[:,1]) * ((((((((data[:,1]) + (data[:,25]))/2.0)) * (((data[:,25]) - (data[:,24]))))) - ((((data[:,24]) + (data[:,25]))/2.0))))) )) +\n",
    "            1.0*np.tanh(((np.where((((data[:,10]) + (np.tanh(((-1.0*(((((data[:,11]) + (data[:,6]))/2.0))))))))/2.0) < -998, ((((((((data[:,20]) / 2.0)) + (data[:,20]))/2.0)) + (data[:,10]))/2.0), np.tanh(((-1.0*(((((((((((data[:,20]) + (data[:,25]))/2.0)) + (data[:,11]))/2.0)) + (data[:,6]))/2.0)))))) )) / 2.0)) +\n",
    "            1.0*np.tanh(np.where(data[:,27] < -998, data[:,25], (((((data[:,13]) + (((np.tanh((((data[:,13]) * 2.0)))) - (np.tanh((((np.tanh((data[:,10]))) - (data[:,25]))))))))/2.0)) * (((data[:,28]) * ((((((data[:,27]) - (data[:,25]))) + (np.tanh((data[:,10]))))/2.0))))) )) +\n",
    "            1.0*np.tanh(((((data[:,29]) * (((data[:,1]) + (data[:,4]))))) - (((((data[:,24]) * (data[:,3]))) * (((np.where(((data[:,1]) * (((data[:,24]) * (data[:,3])))) < -998, data[:,24], np.tanh((data[:,1])) )) * (data[:,7]))))))) +\n",
    "            1.0*np.tanh((((((-1.0*((data[:,15])))) + (((data[:,5]) + ((((((data[:,28]) + ((((data[:,5]) + (data[:,6]))/2.0)))/2.0)) * (data[:,5]))))))) * ((((((((data[:,15]) * ((((data[:,28]) + (data[:,6]))/2.0)))) + (data[:,6]))) + (((data[:,1]) + (data[:,28]))))/2.0)))) +\n",
    "            1.0*np.tanh(((((((((data[:,21]) + (data[:,3]))/2.0)) + (data[:,3]))/2.0)) * ((((((data[:,16]) * 2.0)) + (((data[:,3]) * ((((((data[:,16]) * 2.0)) + (np.where(data[:,21] > -998, ((((data[:,13]) * (data[:,16]))) * (data[:,3])), data[:,12] )))/2.0)))))/2.0)))) +\n",
    "            1.0*np.tanh(np.where(((data[:,10]) / 2.0) > -998, (((((data[:,16]) * (((data[:,6]) * ((-1.0*((data[:,13])))))))) + (np.where((-1.0*((data[:,29]))) > -998, ((data[:,16]) * (((data[:,6]) * ((-1.0*((data[:,15]))))))), data[:,13] )))/2.0), data[:,16] )) +\n",
    "            0.982024*np.tanh(((((((((((data[:,9]) * (data[:,9]))) + (data[:,20]))/2.0)) + (((data[:,16]) * ((((data[:,24]) + (data[:,6]))/2.0)))))/2.0)) * (np.where(np.where(data[:,16] < -998, data[:,24], data[:,9] ) > -998, np.where(((data[:,9]) * (data[:,25])) < -998, data[:,9], data[:,25] ), data[:,9] )))) +\n",
    "            1.0*np.tanh(((((data[:,9]) * (np.where(np.where(data[:,2] > -998, data[:,19], ((((data[:,19]) + (data[:,19]))) + (data[:,6])) ) < -998, data[:,6], ((((((data[:,19]) + (data[:,6]))) + (data[:,1]))) + (data[:,1])) )))) * (data[:,2]))) +\n",
    "            0.972646*np.tanh(np.where(data[:,25] < -998, data[:,10], np.tanh((np.tanh(((((-1.0*((((((((((data[:,13]) + (data[:,25]))/2.0)) + (data[:,25]))/2.0)) - (data[:,10])))))) * (((((-1.0*((((data[:,5]) - (((data[:,6]) + (data[:,25])))))))) + (((data[:,28]) * (data[:,25]))))/2.0))))))) )) +\n",
    "            1.0*np.tanh((((((data[:,22]) * (np.where(np.tanh((data[:,25])) < -998, data[:,25], (((((((data[:,12]) + (data[:,22]))/2.0)) + (np.tanh((((((data[:,25]) * 2.0)) * ((-1.0*((data[:,4])))))))))) / 2.0) )))) + (((data[:,12]) * (((np.tanh((data[:,25]))) / 2.0)))))/2.0)) +\n",
    "            1.0*np.tanh(((data[:,1]) * (((data[:,23]) * ((-1.0*((np.where((((data[:,28]) + (data[:,28]))/2.0) < -998, data[:,28], np.where(data[:,24] < -998, (((data[:,1]) + (np.where(data[:,20] < -998, data[:,24], data[:,28] )))/2.0), (((data[:,13]) + ((((data[:,28]) + (data[:,24]))/2.0)))/2.0) ) ))))))))) +\n",
    "            1.0*np.tanh((((((((((((data[:,15]) + (np.where(np.tanh((data[:,15])) < -998, data[:,14], np.tanh((data[:,21])) )))/2.0)) + (((data[:,14]) * (data[:,13]))))/2.0)) + ((((((data[:,12]) * (data[:,27]))) + (data[:,28]))/2.0)))/2.0)) / 2.0)) +\n",
    "            0.817116*np.tanh(((((data[:,24]) * (data[:,20]))) * ((((((data[:,4]) + ((((((data[:,0]) + (((((data[:,15]) + (((((((data[:,15]) * (data[:,20]))) + (data[:,0]))) + ((-1.0*((data[:,1])))))))) + (data[:,2]))))) + (data[:,18]))/2.0)))/2.0)) + (data[:,2]))))) +\n",
    "            1.0*np.tanh(((((((((data[:,9]) - (data[:,18]))) * (((data[:,13]) * (np.tanh((((((data[:,6]) + (((((data[:,14]) + (((data[:,14]) + (data[:,18]))))) / 2.0)))) - (np.where(data[:,15] < -998, data[:,9], data[:,15] )))))))))) / 2.0)) / 2.0)) +\n",
    "            0.999218*np.tanh((((((-1.0*(((((data[:,27]) + (((((data[:,10]) * (data[:,4]))) - (data[:,3]))))/2.0))))) / 2.0)) * (np.tanh((np.where(data[:,24] < -998, data[:,10], ((data[:,19]) + (data[:,24])) )))))) +\n",
    "            1.0*np.tanh((((((((((np.tanh((((np.tanh((np.tanh((data[:,15]))))) + (np.tanh((data[:,15]))))))) + (np.tanh((data[:,14]))))) + (np.tanh((data[:,19]))))/2.0)) / 2.0)) / 2.0)) +\n",
    "            1.0*np.tanh(((data[:,28]) * (((((np.tanh((((data[:,19]) + (np.tanh((((((data[:,16]) + (((((((data[:,18]) + (data[:,16]))) + (np.tanh((((np.tanh((data[:,24]))) + (data[:,16]))))))) + (data[:,16]))))) + (data[:,29]))))))))) / 2.0)) / 2.0)))) +\n",
    "            1.0*np.tanh((((-1.0*((((((((data[:,18]) * (((data[:,24]) - (np.where(data[:,23] < -998, data[:,8], ((data[:,18]) * (((((-1.0*((((((data[:,9]) - (data[:,23]))) - (data[:,8])))))) + ((((data[:,2]) + (data[:,24]))/2.0)))/2.0))) )))))) / 2.0)) / 2.0))))) / 2.0)))\n",
    "\n",
    "def GPClusterII(data):\n",
    "    return (1.0*np.tanh((((5.02218389511108398)) * (((data[:,25]) + ((((((((((((((((((((data[:,24]) * 2.0)) + (data[:,1]))/2.0)) * 2.0)) + ((((((data[:,24]) * 2.0)) + (data[:,2]))/2.0)))/2.0)) + (data[:,1]))/2.0)) - (data[:,13]))) * 2.0)) - (data[:,6]))))))) +\n",
    "            1.0*np.tanh(((((((data[:,20]) + (((data[:,23]) - (((data[:,9]) - (data[:,24]))))))) - (((data[:,10]) - (((((((data[:,1]) + (((data[:,24]) + ((-1.0*((data[:,13])))))))) - (((data[:,13]) - (data[:,25]))))) * 2.0)))))) * 2.0)) +\n",
    "            1.0*np.tanh(((((np.where(((data[:,6]) + (data[:,13])) > -998, data[:,18], data[:,1] )) - ((((((-1.0*((data[:,2])))) - (((data[:,1]) - (((((data[:,28]) + (((data[:,6]) + (((data[:,13]) * 2.0)))))) + (data[:,16]))))))) * 2.0)))) * 2.0)) +\n",
    "            1.0*np.tanh(((((((data[:,14]) + (data[:,25]))) - (np.where((((-1.0*((data[:,24])))) + (data[:,9])) < -998, data[:,25], data[:,28] )))) - (((data[:,19]) + ((((((((-1.0*((data[:,24])))) - (data[:,1]))) + (((data[:,9]) - (data[:,24]))))) * 2.0)))))) +\n",
    "            1.0*np.tanh(((((((((((data[:,24]) - (data[:,28]))) - (((data[:,13]) + (((data[:,6]) - (data[:,23]))))))) + ((((((data[:,6]) + ((((data[:,24]) + (data[:,20]))/2.0)))/2.0)) - (np.where(data[:,28] > -998, data[:,13], (((data[:,24]) + (data[:,28]))/2.0) )))))) * 2.0)) * 2.0)) +\n",
    "            1.0*np.tanh(((((6.0)) + (((((data[:,24]) + (np.where((7.43536424636840820) < -998, data[:,23], (((((((data[:,23]) + (np.where(data[:,6] > -998, ((data[:,25]) - (((np.tanh((data[:,10]))) - (data[:,24])))), (7.43536424636840820) )))/2.0)) - (np.tanh((data[:,9]))))) * 2.0) )))) * ((6.0)))))/2.0)) +\n",
    "            1.0*np.tanh(((((((((((data[:,25]) + (((((data[:,2]) + (((data[:,1]) + (data[:,24]))))) + (data[:,1]))))) - (np.where(((data[:,13]) * (data[:,13])) < -998, np.where(data[:,1] < -998, data[:,13], data[:,2] ), data[:,13] )))) - (data[:,13]))) - (data[:,6]))) * 2.0)) +\n",
    "            1.0*np.tanh(((data[:,3]) + (((data[:,25]) + (((((((((data[:,1]) - (data[:,13]))) * 2.0)) + (((data[:,24]) - (np.where(data[:,8] < -998, data[:,27], data[:,8] )))))) - (((((data[:,13]) - (data[:,2]))) + (data[:,28]))))))))) +\n",
    "            1.0*np.tanh(((np.where(((data[:,24]) + (data[:,22])) < -998, data[:,13], ((data[:,1]) - (((((data[:,28]) - (((((data[:,24]) + (data[:,22]))) + (data[:,24]))))) + (((data[:,13]) * 2.0))))) )) * 2.0)) +\n",
    "            1.0*np.tanh(((((((data[:,24]) + ((((-1.0*((data[:,28])))) + (((((data[:,13]) * (((data[:,13]) + (data[:,13]))))) - (((((data[:,8]) - (data[:,1]))) - (data[:,1]))))))))) - (((data[:,6]) - (data[:,13]))))) - (((data[:,19]) - (data[:,24]))))) +\n",
    "            1.0*np.tanh(((data[:,1]) + (((data[:,25]) + (((np.where((-1.0*((((data[:,8]) - (((data[:,2]) - (data[:,13]))))))) < -998, data[:,1], data[:,15] )) - (((((data[:,8]) - (((data[:,2]) - (data[:,13]))))) - (((data[:,2]) - (data[:,13]))))))))))) +\n",
    "            1.0*np.tanh(((((data[:,24]) - (((data[:,13]) - (((data[:,24]) - (((data[:,13]) - (((data[:,1]) - (((data[:,13]) - (((data[:,1]) - (((data[:,13]) - (data[:,20]))))))))))))))))) - (np.where(data[:,13] < -998, data[:,13], data[:,19] )))) +\n",
    "            1.0*np.tanh(((((np.tanh(((3.0)))) - (((data[:,13]) + (np.tanh((data[:,28]))))))) + (((((data[:,23]) + (((data[:,24]) + (((((np.tanh(((3.0)))) - (((data[:,13]) + (data[:,6]))))) * 2.0)))))) * 2.0)))) +\n",
    "            1.0*np.tanh((((((((((data[:,15]) + (data[:,23]))/2.0)) - (((data[:,13]) - (((data[:,24]) * (((np.where(data[:,13] < -998, ((data[:,15]) + (data[:,23])), ((data[:,2]) + (data[:,4])) )) + (data[:,2]))))))))) * 2.0)) * 2.0)) +\n",
    "            1.0*np.tanh(((data[:,1]) - (np.where(((((1.15202331542968750)) + (data[:,1]))/2.0) > -998, ((((((data[:,13]) + (((data[:,13]) - (data[:,3]))))) + (((((((data[:,5]) + (data[:,13]))) + ((((data[:,13]) + (data[:,5]))/2.0)))) - ((1.15202331542968750)))))) - (data[:,2])), data[:,13] )))) +\n",
    "            1.0*np.tanh(np.where((((((6.0)) + ((6.0)))) + (data[:,9])) < -998, (6.0), ((((((data[:,1]) + (data[:,24]))) + (data[:,24]))) + (((((data[:,24]) - (data[:,9]))) - ((((data[:,28]) + (((data[:,6]) - ((((6.0)) - (data[:,6]))))))/2.0))))) )) +\n",
    "            1.0*np.tanh(((((((((((((data[:,3]) - (np.where(((data[:,13]) - (data[:,2])) > -998, ((data[:,13]) - (data[:,13])), data[:,3] )))) + (data[:,1]))) - (((((((((data[:,13]) - (data[:,2]))) - (data[:,2]))) - (data[:,1]))) * 2.0)))) * 2.0)) * 2.0)) * 2.0)) +\n",
    "            1.0*np.tanh(((data[:,15]) + (((((data[:,1]) - (((data[:,3]) + ((((data[:,9]) + (data[:,13]))/2.0)))))) - (((data[:,13]) + (((data[:,2]) * (np.where(((data[:,13]) + (data[:,15])) < -998, data[:,13], data[:,15] )))))))))) +\n",
    "            1.0*np.tanh((-1.0*((((data[:,13]) - (((((data[:,23]) * (((((((data[:,23]) + (((data[:,10]) + (((data[:,1]) + (data[:,9]))))))) + (((data[:,10]) + (data[:,1]))))) + (data[:,22]))))) + ((((np.tanh(((5.0)))) + (data[:,22]))/2.0))))))))) +\n",
    "            1.0*np.tanh(np.where(data[:,3] < -998, np.where(data[:,22] < -998, data[:,2], data[:,13] ), ((((data[:,2]) + (data[:,1]))) + (((data[:,13]) * (np.where(((data[:,2]) + (data[:,3])) < -998, ((data[:,1]) * (((data[:,13]) * 2.0))), ((data[:,3]) + (data[:,13])) ))))) )) +\n",
    "            1.0*np.tanh(np.where(data[:,22] < -998, data[:,13], ((((((data[:,1]) + (((((data[:,1]) + (((data[:,5]) * (((data[:,13]) * (data[:,3]))))))) + (data[:,13]))))) + (((data[:,10]) * (data[:,22]))))) + (((data[:,13]) * (data[:,13])))) )) +\n",
    "            1.0*np.tanh(((data[:,2]) + ((((data[:,15]) + (((((((data[:,1]) * (data[:,1]))) - (((data[:,13]) + (((data[:,13]) + (data[:,3]))))))) - ((((np.where(data[:,13] > -998, data[:,3], data[:,1] )) + (((data[:,14]) + (data[:,16]))))/2.0)))))/2.0)))) +\n",
    "            1.0*np.tanh((((np.where(data[:,1] > -998, data[:,2], ((data[:,1]) + (data[:,22])) )) + (((((np.tanh((((((np.tanh(((((((((data[:,1]) + (((data[:,6]) * 2.0)))/2.0)) * 2.0)) + ((((3.0)) + (data[:,9]))))))) * 2.0)) + (data[:,22]))))) * 2.0)) + (data[:,1]))))/2.0)) +\n",
    "            1.0*np.tanh(((data[:,1]) + (((((((data[:,9]) * (data[:,15]))) - (np.where(data[:,9] < -998, data[:,16], (((data[:,13]) + ((((((data[:,13]) + (data[:,9]))) + (data[:,28]))/2.0)))/2.0) )))) - (((data[:,16]) * (data[:,9]))))))) +\n",
    "            1.0*np.tanh((((((((data[:,10]) * (data[:,3]))) + (((((data[:,9]) * (((data[:,15]) + (data[:,20]))))) - ((-1.0*((((((data[:,10]) * (((data[:,20]) + (((data[:,15]) + (data[:,3]))))))) - ((-1.0*((np.tanh(((5.0)))))))))))))))) + (data[:,1]))/2.0)) +\n",
    "            1.0*np.tanh((((((data[:,1]) * (((data[:,1]) * (data[:,1]))))) + (((((((data[:,0]) - (data[:,28]))) - (data[:,28]))) * (((data[:,13]) + (((data[:,8]) + (((np.where(data[:,9] < -998, data[:,10], ((data[:,13]) - (data[:,25])) )) + (data[:,9]))))))))))/2.0)) +\n",
    "            1.0*np.tanh((((((((data[:,1]) * 2.0)) * (data[:,23]))) + ((((((((data[:,18]) - (data[:,20]))) * (((data[:,18]) - (data[:,23]))))) + (((data[:,11]) + (((((data[:,10]) * (data[:,18]))) * (np.where(data[:,23] > -998, data[:,16], data[:,11] )))))))/2.0)))/2.0)) +\n",
    "            1.0*np.tanh((((np.where(data[:,1] > -998, ((data[:,13]) * (data[:,3])), ((data[:,13]) * (data[:,3])) )) + (((((((((data[:,4]) + (((((data[:,13]) + (data[:,1]))) * 2.0)))) + (((data[:,23]) + (data[:,1]))))) * 2.0)) * (((data[:,2]) + (data[:,1]))))))/2.0)) +\n",
    "            1.0*np.tanh(((np.tanh((((((data[:,13]) - (((np.tanh((((data[:,23]) - (np.where((-1.0*((data[:,23]))) < -998, data[:,23], data[:,6] )))))) * 2.0)))) - (data[:,23]))))) + (data[:,23]))) +\n",
    "            1.0*np.tanh(((np.where(data[:,1] < -998, data[:,13], data[:,1] )) + ((-1.0*(((((((data[:,13]) * ((((data[:,15]) + (data[:,1]))/2.0)))) + ((((((data[:,13]) * (data[:,14]))) + (np.where(data[:,13] > -998, data[:,4], data[:,4] )))/2.0)))/2.0))))))) +\n",
    "            1.0*np.tanh((((((data[:,13]) * ((((((((data[:,3]) * (data[:,16]))) - (data[:,14]))) + (((data[:,18]) - (data[:,16]))))/2.0)))) + (np.where(data[:,3] > -998, ((((data[:,23]) * 2.0)) * (data[:,1])), (-1.0*((data[:,7]))) )))/2.0)) +\n",
    "            1.0*np.tanh((((data[:,1]) + ((-1.0*((((((((data[:,18]) + (((((data[:,22]) * (data[:,16]))) + (((data[:,3]) * (data[:,16]))))))) / 2.0)) + (np.tanh((((((data[:,16]) + (data[:,18]))) * (((data[:,6]) - (data[:,18])))))))))))))/2.0)) +\n",
    "            1.0*np.tanh(((data[:,1]) - (((data[:,16]) * ((((((((data[:,15]) + (data[:,6]))/2.0)) + ((((((data[:,15]) + ((((((data[:,15]) + (data[:,6]))/2.0)) * (data[:,22]))))/2.0)) * (data[:,6]))))) + ((((((data[:,6]) + (data[:,15]))/2.0)) * (data[:,13]))))))))) +\n",
    "            1.0*np.tanh(((((data[:,29]) + (((np.where(data[:,23] > -998, ((((((-1.0*((data[:,2])))) + (data[:,23]))/2.0)) * (((data[:,23]) + (data[:,2])))), data[:,23] )) + (((data[:,23]) + (data[:,21]))))))) * (((data[:,29]) + (data[:,1]))))) +\n",
    "            1.0*np.tanh(((((((((data[:,1]) + ((0.16913299262523651)))/2.0)) + ((-1.0*((np.where((0.16913299262523651) < -998, data[:,24], ((data[:,4]) * (((data[:,25]) * ((((((data[:,24]) * ((((data[:,24]) + (np.where(data[:,29] < -998, (0.16913299262523651), data[:,25] )))/2.0)))) + (np.tanh((data[:,24]))))/2.0))))) ))))))/2.0)) * 2.0)) +\n",
    "            1.0*np.tanh(((np.tanh((data[:,15]))) * ((-1.0*((((data[:,3]) * ((((data[:,13]) + (np.where((((-1.0*((((data[:,3]) * (np.tanh((((data[:,17]) * (((data[:,28]) * 2.0))))))))))) * (data[:,15])) > -998, data[:,9], data[:,15] )))/2.0))))))))) +\n",
    "            1.0*np.tanh(((data[:,29]) + (((data[:,2]) * (((((((np.where((((data[:,29]) + (((data[:,13]) * (data[:,1]))))/2.0) > -998, ((((data[:,13]) * (data[:,15]))) - (data[:,15])), (1.0) )) - (((((1.0)) + (data[:,1]))/2.0)))) - (data[:,1]))) - (data[:,24]))))))) +\n",
    "            1.0*np.tanh(((data[:,9]) * (((np.tanh((data[:,15]))) * (((((((data[:,4]) * (np.tanh((((data[:,10]) * (((data[:,4]) * (np.tanh((np.tanh((data[:,15]))))))))))))) * ((((((data[:,10]) * (data[:,28]))) + (data[:,10]))/2.0)))) - (data[:,28]))))))) +\n",
    "            0.982024*np.tanh(((((((np.tanh((np.tanh(((((((-1.0*((data[:,0])))) + (data[:,16]))) + ((((((data[:,16]) * (((data[:,16]) * (data[:,24]))))) + (data[:,15]))/2.0)))))))) + (data[:,23]))) * (data[:,24]))) * (((((-1.0*((data[:,23])))) + (data[:,15]))/2.0)))) +\n",
    "            1.0*np.tanh(((data[:,28]) * (((((data[:,28]) * (((((data[:,19]) - (((data[:,16]) + (((((-1.0*((data[:,14])))) + ((((((data[:,15]) + ((((((data[:,15]) + (((((data[:,28]) / 2.0)) / 2.0)))/2.0)) * (data[:,28]))))/2.0)) * (data[:,28]))))/2.0)))))) / 2.0)))) / 2.0)))) +\n",
    "            0.972646*np.tanh(((data[:,29]) * (np.where(np.where(data[:,27] < -998, ((data[:,29]) * (((data[:,29]) * (data[:,29])))), data[:,29] ) < -998, data[:,4], ((data[:,27]) * (((((np.tanh((np.tanh((((data[:,4]) * 2.0)))))) * 2.0)) * 2.0))) )))) +\n",
    "            1.0*np.tanh((-1.0*((((data[:,12]) * (np.where(data[:,13] < -998, data[:,13], ((np.tanh(((((data[:,13]) + (np.where(data[:,12] < -998, data[:,12], ((((((((data[:,12]) * (((data[:,12]) / 2.0)))) / 2.0)) / 2.0)) / 2.0) )))/2.0)))) / 2.0) ))))))) +\n",
    "            1.0*np.tanh(((data[:,29]) * (((((data[:,26]) + (((((((np.tanh((data[:,14]))) + (data[:,29]))) + (((((data[:,29]) + (data[:,14]))) + (((data[:,29]) + (data[:,27]))))))) - (data[:,7]))))) + (((((data[:,28]) + (data[:,29]))) * (data[:,27]))))))) +\n",
    "            1.0*np.tanh(((np.tanh((((((((data[:,27]) - (((data[:,6]) * (data[:,16]))))) - (((data[:,9]) * (((data[:,6]) * (data[:,18]))))))) - (((data[:,9]) * (((((data[:,6]) * (data[:,27]))) - (((data[:,18]) * (data[:,27]))))))))))) / 2.0)) +\n",
    "            0.817116*np.tanh(((data[:,1]) * ((((((data[:,11]) + (data[:,1]))) + ((((((data[:,24]) + (((data[:,1]) - ((0.60339701175689697)))))/2.0)) + (((((data[:,4]) - ((0.60340058803558350)))) + (((data[:,1]) + (((data[:,23]) + (data[:,3]))))))))))/2.0)))) +\n",
    "            1.0*np.tanh(((((((((((data[:,13]) / 2.0)) - (np.where(data[:,15] < -998, ((data[:,0]) * (((data[:,24]) * (data[:,13])))), ((data[:,15]) + (data[:,24])) )))) / 2.0)) / 2.0)) * (((data[:,0]) * (data[:,13]))))) +\n",
    "            0.999218*np.tanh(((((((-1.0*((((((data[:,22]) * (data[:,19]))) / 2.0))))) + ((((((data[:,20]) + (data[:,14]))/2.0)) * (np.where((-1.0*((((((data[:,22]) * (((data[:,19]) / 2.0)))) / 2.0)))) < -998, data[:,22], np.tanh((data[:,15])) )))))/2.0)) / 2.0)) +\n",
    "            1.0*np.tanh((((((data[:,21]) + (np.where(np.tanh((data[:,25])) < -998, data[:,9], ((data[:,5]) * (((((data[:,9]) * ((((data[:,10]) + (data[:,25]))/2.0)))) * (((((data[:,9]) - (data[:,25]))) * (data[:,13])))))) )))/2.0)) * (((data[:,25]) - (np.tanh((data[:,25]))))))) +\n",
    "            1.0*np.tanh((((((((data[:,0]) - (data[:,4]))) + (((data[:,22]) * (data[:,20]))))/2.0)) * ((((((((((data[:,4]) - (data[:,19]))) + (((((((((data[:,22]) * (data[:,22]))) + (((data[:,20]) * (data[:,22]))))/2.0)) + (data[:,6]))/2.0)))/2.0)) * (data[:,16]))) / 2.0)))) +\n",
    "            1.0*np.tanh(((np.where(data[:,7] < -998, np.tanh((data[:,7])), (((np.tanh((data[:,28]))) + ((((data[:,27]) + (((np.tanh((((data[:,11]) + (data[:,7]))))) * (data[:,28]))))/2.0)))/2.0) )) / 2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:27:34.450789Z",
     "start_time": "2019-11-06T13:27:34.447583Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/org_process.csv\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/train.csv\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/location-eda-8eb410-556827.ipynb\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/new_process.csv\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/nfl-big-data-bowl-2020.zip\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/train_basetable.csv\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/new.ipynb\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/.ipynb_checkpoints/location-eda-8eb410-556827-checkpoint.ipynb\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/.ipynb_checkpoints/new_process-checkpoint.csv\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/.ipynb_checkpoints/org_process-checkpoint.csv\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/.ipynb_checkpoints/train-checkpoint.csv\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/.ipynb_checkpoints/new-checkpoint.ipynb\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/kaggle/competitions/nflrush/__init__.py\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/kaggle/competitions/nflrush/sample_submission.csv.encrypted\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/kaggle/competitions/nflrush/test.csv.encrypted\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/kaggle/competitions/nflrush/competition.cpython-36m-x86_64-linux-gnu.so\n",
      "/home/jupyter/Datas/NFL_Big_Data_Bowl/kaggle/competitions/nflrush/.ipynb_checkpoints/__init__-checkpoint.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/home/jupyter/Datas/NFL_Big_Data_Bowl'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:27:37.305506Z",
     "start_time": "2019-11-06T13:27:34.452843Z"
    }
   },
   "outputs": [],
   "source": [
    "# train = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})\n",
    "if TRAIN_OFFLINE:\n",
    "    train = pd.read_csv('/home/jupyter/Datas/NFL_Big_Data_Bowl/train.csv', dtype={'WindSpeed': 'object'})\n",
    "else:\n",
    "    train = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:27:37.336457Z",
     "start_time": "2019-11-06T13:27:37.308386Z"
    }
   },
   "outputs": [],
   "source": [
    "outcomes = train[['GameId','PlayId','Yards']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:27:37.385294Z",
     "start_time": "2019-11-06T13:27:37.340021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameId</th>\n",
       "      <th>PlayId</th>\n",
       "      <th>Team</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>S</th>\n",
       "      <th>A</th>\n",
       "      <th>Dis</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Dir</th>\n",
       "      <th>NflId</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>JerseyNumber</th>\n",
       "      <th>Season</th>\n",
       "      <th>YardLine</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>GameClock</th>\n",
       "      <th>PossessionTeam</th>\n",
       "      <th>Down</th>\n",
       "      <th>Distance</th>\n",
       "      <th>FieldPosition</th>\n",
       "      <th>HomeScoreBeforePlay</th>\n",
       "      <th>VisitorScoreBeforePlay</th>\n",
       "      <th>NflIdRusher</th>\n",
       "      <th>OffenseFormation</th>\n",
       "      <th>OffensePersonnel</th>\n",
       "      <th>DefendersInTheBox</th>\n",
       "      <th>DefensePersonnel</th>\n",
       "      <th>PlayDirection</th>\n",
       "      <th>TimeHandoff</th>\n",
       "      <th>TimeSnap</th>\n",
       "      <th>Yards</th>\n",
       "      <th>PlayerHeight</th>\n",
       "      <th>PlayerWeight</th>\n",
       "      <th>PlayerBirthDate</th>\n",
       "      <th>PlayerCollegeName</th>\n",
       "      <th>Position</th>\n",
       "      <th>HomeTeamAbbr</th>\n",
       "      <th>VisitorTeamAbbr</th>\n",
       "      <th>Week</th>\n",
       "      <th>Stadium</th>\n",
       "      <th>Location</th>\n",
       "      <th>StadiumType</th>\n",
       "      <th>Turf</th>\n",
       "      <th>GameWeather</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDirection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000118</td>\n",
       "      <td>away</td>\n",
       "      <td>73.91</td>\n",
       "      <td>34.84</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.40</td>\n",
       "      <td>81.99</td>\n",
       "      <td>177.18</td>\n",
       "      <td>496723</td>\n",
       "      <td>Eric Berry</td>\n",
       "      <td>29</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>14:14:00</td>\n",
       "      <td>NE</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2543773</td>\n",
       "      <td>SHOTGUN</td>\n",
       "      <td>1 RB, 1 TE, 3 WR</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2 DL, 3 LB, 6 DB</td>\n",
       "      <td>left</td>\n",
       "      <td>2017-09-08T00:44:06.000Z</td>\n",
       "      <td>2017-09-08T00:44:05.000Z</td>\n",
       "      <td>8</td>\n",
       "      <td>6-0</td>\n",
       "      <td>212</td>\n",
       "      <td>12/29/1988</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>SS</td>\n",
       "      <td>NE</td>\n",
       "      <td>KC</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000118</td>\n",
       "      <td>away</td>\n",
       "      <td>74.67</td>\n",
       "      <td>32.64</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.01</td>\n",
       "      <td>27.61</td>\n",
       "      <td>198.70</td>\n",
       "      <td>2495116</td>\n",
       "      <td>Allen Bailey</td>\n",
       "      <td>97</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>14:14:00</td>\n",
       "      <td>NE</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2543773</td>\n",
       "      <td>SHOTGUN</td>\n",
       "      <td>1 RB, 1 TE, 3 WR</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2 DL, 3 LB, 6 DB</td>\n",
       "      <td>left</td>\n",
       "      <td>2017-09-08T00:44:06.000Z</td>\n",
       "      <td>2017-09-08T00:44:05.000Z</td>\n",
       "      <td>8</td>\n",
       "      <td>6-3</td>\n",
       "      <td>288</td>\n",
       "      <td>03/25/1989</td>\n",
       "      <td>Miami</td>\n",
       "      <td>DE</td>\n",
       "      <td>NE</td>\n",
       "      <td>KC</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000118</td>\n",
       "      <td>away</td>\n",
       "      <td>74.00</td>\n",
       "      <td>33.20</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.31</td>\n",
       "      <td>3.01</td>\n",
       "      <td>202.73</td>\n",
       "      <td>2495493</td>\n",
       "      <td>Justin Houston</td>\n",
       "      <td>50</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>14:14:00</td>\n",
       "      <td>NE</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2543773</td>\n",
       "      <td>SHOTGUN</td>\n",
       "      <td>1 RB, 1 TE, 3 WR</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2 DL, 3 LB, 6 DB</td>\n",
       "      <td>left</td>\n",
       "      <td>2017-09-08T00:44:06.000Z</td>\n",
       "      <td>2017-09-08T00:44:05.000Z</td>\n",
       "      <td>8</td>\n",
       "      <td>6-3</td>\n",
       "      <td>270</td>\n",
       "      <td>01/21/1989</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>DE</td>\n",
       "      <td>NE</td>\n",
       "      <td>KC</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000118</td>\n",
       "      <td>away</td>\n",
       "      <td>71.46</td>\n",
       "      <td>27.70</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.02</td>\n",
       "      <td>359.77</td>\n",
       "      <td>105.64</td>\n",
       "      <td>2506353</td>\n",
       "      <td>Derrick Johnson</td>\n",
       "      <td>56</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>14:14:00</td>\n",
       "      <td>NE</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2543773</td>\n",
       "      <td>SHOTGUN</td>\n",
       "      <td>1 RB, 1 TE, 3 WR</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2 DL, 3 LB, 6 DB</td>\n",
       "      <td>left</td>\n",
       "      <td>2017-09-08T00:44:06.000Z</td>\n",
       "      <td>2017-09-08T00:44:05.000Z</td>\n",
       "      <td>8</td>\n",
       "      <td>6-3</td>\n",
       "      <td>245</td>\n",
       "      <td>11/22/1982</td>\n",
       "      <td>Texas</td>\n",
       "      <td>ILB</td>\n",
       "      <td>NE</td>\n",
       "      <td>KC</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000118</td>\n",
       "      <td>away</td>\n",
       "      <td>69.32</td>\n",
       "      <td>35.42</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.16</td>\n",
       "      <td>12.63</td>\n",
       "      <td>164.31</td>\n",
       "      <td>2530794</td>\n",
       "      <td>Ron Parker</td>\n",
       "      <td>38</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>14:14:00</td>\n",
       "      <td>NE</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2543773</td>\n",
       "      <td>SHOTGUN</td>\n",
       "      <td>1 RB, 1 TE, 3 WR</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2 DL, 3 LB, 6 DB</td>\n",
       "      <td>left</td>\n",
       "      <td>2017-09-08T00:44:06.000Z</td>\n",
       "      <td>2017-09-08T00:44:05.000Z</td>\n",
       "      <td>8</td>\n",
       "      <td>6-0</td>\n",
       "      <td>206</td>\n",
       "      <td>08/17/1987</td>\n",
       "      <td>Newberry</td>\n",
       "      <td>FS</td>\n",
       "      <td>NE</td>\n",
       "      <td>KC</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GameId          PlayId  Team      X      Y     S     A   Dis  \\\n",
       "0  2017090700  20170907000118  away  73.91  34.84  1.69  1.13  0.40   \n",
       "1  2017090700  20170907000118  away  74.67  32.64  0.42  1.35  0.01   \n",
       "2  2017090700  20170907000118  away  74.00  33.20  1.22  0.59  0.31   \n",
       "3  2017090700  20170907000118  away  71.46  27.70  0.42  0.54  0.02   \n",
       "4  2017090700  20170907000118  away  69.32  35.42  1.82  2.43  0.16   \n",
       "\n",
       "   Orientation     Dir    NflId      DisplayName  JerseyNumber  Season  \\\n",
       "0        81.99  177.18   496723       Eric Berry            29    2017   \n",
       "1        27.61  198.70  2495116     Allen Bailey            97    2017   \n",
       "2         3.01  202.73  2495493   Justin Houston            50    2017   \n",
       "3       359.77  105.64  2506353  Derrick Johnson            56    2017   \n",
       "4        12.63  164.31  2530794       Ron Parker            38    2017   \n",
       "\n",
       "   YardLine  Quarter GameClock PossessionTeam  Down  Distance FieldPosition  \\\n",
       "0        35        1  14:14:00             NE     3         2            NE   \n",
       "1        35        1  14:14:00             NE     3         2            NE   \n",
       "2        35        1  14:14:00             NE     3         2            NE   \n",
       "3        35        1  14:14:00             NE     3         2            NE   \n",
       "4        35        1  14:14:00             NE     3         2            NE   \n",
       "\n",
       "   HomeScoreBeforePlay  VisitorScoreBeforePlay  NflIdRusher OffenseFormation  \\\n",
       "0                    0                       0      2543773          SHOTGUN   \n",
       "1                    0                       0      2543773          SHOTGUN   \n",
       "2                    0                       0      2543773          SHOTGUN   \n",
       "3                    0                       0      2543773          SHOTGUN   \n",
       "4                    0                       0      2543773          SHOTGUN   \n",
       "\n",
       "   OffensePersonnel  DefendersInTheBox  DefensePersonnel PlayDirection  \\\n",
       "0  1 RB, 1 TE, 3 WR                6.0  2 DL, 3 LB, 6 DB          left   \n",
       "1  1 RB, 1 TE, 3 WR                6.0  2 DL, 3 LB, 6 DB          left   \n",
       "2  1 RB, 1 TE, 3 WR                6.0  2 DL, 3 LB, 6 DB          left   \n",
       "3  1 RB, 1 TE, 3 WR                6.0  2 DL, 3 LB, 6 DB          left   \n",
       "4  1 RB, 1 TE, 3 WR                6.0  2 DL, 3 LB, 6 DB          left   \n",
       "\n",
       "                TimeHandoff                  TimeSnap  Yards PlayerHeight  \\\n",
       "0  2017-09-08T00:44:06.000Z  2017-09-08T00:44:05.000Z      8          6-0   \n",
       "1  2017-09-08T00:44:06.000Z  2017-09-08T00:44:05.000Z      8          6-3   \n",
       "2  2017-09-08T00:44:06.000Z  2017-09-08T00:44:05.000Z      8          6-3   \n",
       "3  2017-09-08T00:44:06.000Z  2017-09-08T00:44:05.000Z      8          6-3   \n",
       "4  2017-09-08T00:44:06.000Z  2017-09-08T00:44:05.000Z      8          6-0   \n",
       "\n",
       "   PlayerWeight PlayerBirthDate PlayerCollegeName Position HomeTeamAbbr  \\\n",
       "0           212      12/29/1988         Tennessee       SS           NE   \n",
       "1           288      03/25/1989             Miami       DE           NE   \n",
       "2           270      01/21/1989           Georgia       DE           NE   \n",
       "3           245      11/22/1982             Texas      ILB           NE   \n",
       "4           206      08/17/1987          Newberry       FS           NE   \n",
       "\n",
       "  VisitorTeamAbbr  Week           Stadium        Location StadiumType  \\\n",
       "0              KC     1  Gillette Stadium  Foxborough, MA     Outdoor   \n",
       "1              KC     1  Gillette Stadium  Foxborough, MA     Outdoor   \n",
       "2              KC     1  Gillette Stadium  Foxborough, MA     Outdoor   \n",
       "3              KC     1  Gillette Stadium  Foxborough, MA     Outdoor   \n",
       "4              KC     1  Gillette Stadium  Foxborough, MA     Outdoor   \n",
       "\n",
       "         Turf     GameWeather  Temperature  Humidity WindSpeed WindDirection  \n",
       "0  Field Turf  Clear and warm         63.0      77.0         8            SW  \n",
       "1  Field Turf  Clear and warm         63.0      77.0         8            SW  \n",
       "2  Field Turf  Clear and warm         63.0      77.0         8            SW  \n",
       "3  Field Turf  Clear and warm         63.0      77.0         8            SW  \n",
       "4  Field Turf  Clear and warm         63.0      77.0         8            SW  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:27:38.130612Z",
     "start_time": "2019-11-06T13:27:38.110539Z"
    }
   },
   "outputs": [],
   "source": [
    "def strtoseconds(txt):\n",
    "    txt = txt.split(':')\n",
    "    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n",
    "    return ans\n",
    "\n",
    "def strtofloat(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def map_weather(txt):\n",
    "    ans = 1\n",
    "    if pd.isna(txt):\n",
    "        return 0\n",
    "    if 'partly' in txt:\n",
    "        ans*=0.5\n",
    "    if 'climate controlled' in txt or 'indoor' in txt:\n",
    "        return ans*3\n",
    "    if 'sunny' in txt or 'sun' in txt:\n",
    "        return ans*2\n",
    "    if 'clear' in txt:\n",
    "        return ans\n",
    "    if 'cloudy' in txt:\n",
    "        return -ans\n",
    "    if 'rain' in txt or 'rainy' in txt:\n",
    "        return -2*ans\n",
    "    if 'snow' in txt:\n",
    "        return -3*ans\n",
    "    return 0\n",
    "\n",
    "def OffensePersonnelSplit(x):\n",
    "    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0, 'QB' : 0, 'RB' : 0, 'TE' : 0, 'WR' : 0}\n",
    "    for xx in x.split(\",\"):\n",
    "        xxs = xx.split(\" \")\n",
    "        dic[xxs[-1]] = int(xxs[-2])\n",
    "    return dic\n",
    "\n",
    "def DefensePersonnelSplit(x):\n",
    "    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n",
    "    for xx in x.split(\",\"):\n",
    "        xxs = xx.split(\" \")\n",
    "        dic[xxs[-1]] = int(xxs[-2])\n",
    "    return dic\n",
    "\n",
    "def orientation_to_cat(x):\n",
    "    x = np.clip(x, 0, 360 - 1)\n",
    "    try:\n",
    "        return str(int(x/15))\n",
    "    except:\n",
    "        return \"nan\"\n",
    "def preprocess(train):\n",
    "    ## GameClock\n",
    "    train['GameClock_sec'] = train['GameClock'].apply(strtoseconds)\n",
    "    train[\"GameClock_minute\"] = train[\"GameClock\"].apply(lambda x : x.split(\":\")[0]).astype(\"object\")\n",
    "\n",
    "    ## Height\n",
    "    train['PlayerHeight_dense'] = train['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n",
    "\n",
    "    ## Time\n",
    "    train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    train['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "\n",
    "    train['TimeDelta'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n",
    "    train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "\n",
    "    ## Age\n",
    "    seconds_in_year = 60*60*24*365.25\n",
    "    train['PlayerAge'] = train.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n",
    "    train[\"PlayerAge_ob\"] = train['PlayerAge'].astype(np.int).astype(\"object\")\n",
    "\n",
    "    ## WindSpeed\n",
    "    train['WindSpeed_ob'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "    train['WindSpeed_dense'] = train['WindSpeed_ob'].apply(strtofloat)\n",
    "\n",
    "    ## Weather\n",
    "    train['GameWeather_process'] = train['GameWeather'].str.lower()\n",
    "    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n",
    "    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n",
    "    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n",
    "    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n",
    "    train['GameWeather_dense'] = train['GameWeather_process'].apply(map_weather)\n",
    "\n",
    "    ## Rusher\n",
    "    train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n",
    "    train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n",
    "    temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n",
    "    train = train.merge(temp, on = \"PlayId\")\n",
    "    train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n",
    "\n",
    "    ## dense -> categorical\n",
    "    train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n",
    "    train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n",
    "    train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n",
    "    train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n",
    "    # train[\"DefendersInTheBox_ob\"] = train[\"DefendersInTheBox\"].astype(\"object\")\n",
    "    # train[\"Week_ob\"] = train[\"Week\"].astype(\"object\")\n",
    "    # train[\"TimeDelta_ob\"] = train[\"TimeDelta\"].astype(\"object\")\n",
    "\n",
    "\n",
    "    ## Orientation and Dir\n",
    "    train[\"Orientation_ob\"] = train[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n",
    "    train[\"Dir_ob\"] = train[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n",
    "\n",
    "    train[\"Orientation_sin\"] = train[\"Orientation\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    train[\"Orientation_cos\"] = train[\"Orientation\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "    train[\"Dir_sin\"] = train[\"Dir\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    train[\"Dir_cos\"] = train[\"Dir\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "\n",
    "    ## diff Score\n",
    "    train[\"diffScoreBeforePlay\"] = train[\"HomeScoreBeforePlay\"] - train[\"VisitorScoreBeforePlay\"]\n",
    "    train[\"diffScoreBeforePlay_binary_ob\"] = (train[\"HomeScoreBeforePlay\"] > train[\"VisitorScoreBeforePlay\"]).astype(\"object\")\n",
    "\n",
    "    ## Turf\n",
    "    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', 'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', 'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n",
    "    train['Turf'] = train['Turf'].map(Turf)\n",
    "\n",
    "    ## OffensePersonnel\n",
    "    temp = train[\"OffensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(OffensePersonnelSplit(x)))\n",
    "    temp.columns = [\"Offense\" + c for c in temp.columns]\n",
    "    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n",
    "    train = train.merge(temp, on = \"PlayId\")\n",
    "\n",
    "    ## DefensePersonnel\n",
    "    temp = train[\"DefensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(DefensePersonnelSplit(x)))\n",
    "    temp.columns = [\"Defense\" + c for c in temp.columns]\n",
    "    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n",
    "    train = train.merge(temp, on = \"PlayId\")\n",
    "\n",
    "    ## sort\n",
    "#     train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index(drop = True)\n",
    "    train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'IsRusherTeam', 'IsRusher']).reset_index(drop = True)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for anchoring offense moving left from {0,0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:27:38.156575Z",
     "start_time": "2019-11-06T13:27:38.132416Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_features(df, deploy=False):\n",
    "    if(df.loc[df.Season==2017,'Orientation'].shape[0]!=0):\n",
    "        df.loc[df.Season==2017,'Orientation'] = (df.loc[df.Season==2017,'Orientation']+90)%360\n",
    "    def new_X(x_coordinate, play_direction):\n",
    "        if play_direction == 'left':\n",
    "            return 120.0 - x_coordinate\n",
    "        else:\n",
    "            return x_coordinate\n",
    "\n",
    "    def new_line(rush_team, field_position, yardline):\n",
    "        if rush_team == field_position:\n",
    "            # offense starting at X = 0 plus the 10 yard endzone plus the line of scrimmage\n",
    "            return 10.0 + yardline\n",
    "        else:\n",
    "            # half the field plus the yards between midfield and the line of scrimmage\n",
    "            return 60.0 + (50 - yardline)\n",
    "\n",
    "    def new_orientation(angle, play_direction):\n",
    "        if play_direction == 'left':\n",
    "            new_angle = 360.0 - angle\n",
    "            if new_angle == 360.0:\n",
    "                new_angle = 0.0\n",
    "            return new_angle\n",
    "        else:\n",
    "            return angle\n",
    "\n",
    "    def euclidean_distance(x1,y1,x2,y2):\n",
    "        x_diff = (x1-x2)**2\n",
    "        y_diff = (y1-y2)**2\n",
    "\n",
    "        return np.sqrt(x_diff + y_diff)\n",
    "\n",
    "    def back_direction(orientation):\n",
    "        if orientation > 180.0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def update_yardline(df):\n",
    "        new_yardline = df[df['NflId'] == df['NflIdRusher']]\n",
    "        new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: new_line(x[0],x[1],x[2]), axis=1)\n",
    "        new_yardline = new_yardline[['GameId','PlayId','YardLine']]\n",
    "\n",
    "        return new_yardline\n",
    "\n",
    "    def update_orientation(df, yardline):\n",
    "        df['X'] = df[['X','PlayDirection']].apply(lambda x: new_X(x[0],x[1]), axis=1)\n",
    "        df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n",
    "        df['Dir'] = df[['Dir','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n",
    "\n",
    "        df = df.drop('YardLine', axis=1)\n",
    "        df = pd.merge(df, yardline, on=['GameId','PlayId'], how='inner')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def back_features(df):\n",
    "        carriers = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','NflIdRusher','X','Y','Orientation','Dir','YardLine']]\n",
    "        carriers['back_from_scrimmage'] = carriers['YardLine'] - carriers['X']\n",
    "        carriers['back_oriented_down_field'] = carriers['Orientation'].apply(lambda x: back_direction(x))\n",
    "        carriers['back_moving_down_field'] = carriers['Dir'].apply(lambda x: back_direction(x))\n",
    "        carriers = carriers.rename(columns={'X':'back_X',\n",
    "                                            'Y':'back_Y'})\n",
    "        carriers = carriers[['GameId','PlayId','NflIdRusher','back_X','back_Y','back_from_scrimmage','back_oriented_down_field','back_moving_down_field']]\n",
    "\n",
    "        return carriers\n",
    "\n",
    "    def features_relative_to_back(df, carriers):\n",
    "        player_distance = df[['GameId','PlayId','NflId','X','Y']]\n",
    "        player_distance = pd.merge(player_distance, carriers, on=['GameId','PlayId'], how='inner')\n",
    "        player_distance = player_distance[player_distance['NflId'] != player_distance['NflIdRusher']]\n",
    "        player_distance['dist_to_back'] = player_distance[['X','Y','back_X','back_Y']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n",
    "\n",
    "        player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field'])\\\n",
    "                                         .agg({'dist_to_back':['min','max','mean','std']})\\\n",
    "                                         .reset_index()\n",
    "        player_distance.columns = ['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field',\n",
    "                                   'min_dist','max_dist','mean_dist','std_dist']\n",
    "\n",
    "        return player_distance\n",
    "\n",
    "    def defense_features(df):\n",
    "        rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Team','X','Y']]\n",
    "        rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n",
    "\n",
    "        defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n",
    "        defense = defense[defense['Team'] != defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n",
    "        defense['def_dist_to_back'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n",
    "\n",
    "        defense = defense.groupby(['GameId','PlayId'])\\\n",
    "                         .agg({'def_dist_to_back':['min','max','mean','std']})\\\n",
    "                         .reset_index()\n",
    "        defense.columns = ['GameId','PlayId','def_min_dist','def_max_dist','def_mean_dist','def_std_dist']\n",
    "\n",
    "        return defense\n",
    "\n",
    "    def static_features(df):\n",
    "        \n",
    "        \n",
    "        add_new_feas = []\n",
    "\n",
    "        ## Height\n",
    "        df['PlayerHeight_dense'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n",
    "        \n",
    "        add_new_feas.append('PlayerHeight_dense')\n",
    "\n",
    "        ## Time\n",
    "        df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "        df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "\n",
    "        df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n",
    "        df['PlayerBirthDate'] =df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "\n",
    "        ## Age\n",
    "        seconds_in_year = 60*60*24*365.25\n",
    "        df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n",
    "        add_new_feas.append('PlayerAge')\n",
    "\n",
    "        ## WindSpeed\n",
    "        df['WindSpeed_ob'] = df['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "        df['WindSpeed_ob'] = df['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "        df['WindSpeed_ob'] = df['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "        df['WindSpeed_dense'] = df['WindSpeed_ob'].apply(strtofloat)\n",
    "        add_new_feas.append('WindSpeed_dense')\n",
    "\n",
    "        ## Weather\n",
    "        df['GameWeather_process'] = df['GameWeather'].str.lower()\n",
    "        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n",
    "        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n",
    "        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n",
    "        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n",
    "        df['GameWeather_dense'] = df['GameWeather_process'].apply(map_weather)\n",
    "        add_new_feas.append('GameWeather_dense')\n",
    "#         ## Rusher\n",
    "#         train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n",
    "#         train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n",
    "#         temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n",
    "#         train = train.merge(temp, on = \"PlayId\")\n",
    "#         train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n",
    "\n",
    "        ## dense -> categorical\n",
    "#         train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n",
    "#         train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n",
    "#         train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n",
    "#         train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n",
    "        # train[\"DefendersInTheBox_ob\"] = train[\"DefendersInTheBox\"].astype(\"object\")\n",
    "        # train[\"Week_ob\"] = train[\"Week\"].astype(\"object\")\n",
    "        # train[\"TimeDelta_ob\"] = train[\"TimeDelta\"].astype(\"object\")\n",
    "\n",
    "\n",
    "        ## Orientation and Dir\n",
    "        df[\"Orientation_ob\"] = df[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n",
    "        df[\"Dir_ob\"] = df[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n",
    "\n",
    "        df[\"Orientation_sin\"] = df[\"Orientation\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "        df[\"Orientation_cos\"] = df[\"Orientation\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "        df[\"Dir_sin\"] = df[\"Dir\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "        df[\"Dir_cos\"] = df[\"Dir\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "        add_new_feas.append(\"Dir_sin\")\n",
    "        add_new_feas.append(\"Dir_cos\")\n",
    "        \n",
    "        #Horizontal and Vertical speed\n",
    "        df[\"SDir_sin\"] = df[\"Dir_sin\"].multiply(df[\"S\"])\n",
    "        df[\"SDir_cos\"] = df[\"Dir_cos\"].multiply(df[\"S\"])\n",
    "        add_new_feas.append(\"SDir_sin\")\n",
    "        add_new_feas.append(\"SDir_cos\")\n",
    "\n",
    "\n",
    "        ## diff Score\n",
    "        df[\"diffScoreBeforePlay\"] = df[\"HomeScoreBeforePlay\"] - df[\"VisitorScoreBeforePlay\"]\n",
    "        add_new_feas.append(\"diffScoreBeforePlay\")\n",
    "        \n",
    "    \n",
    "    \n",
    "        static_features = df[df['NflId'] == df['NflIdRusher']][add_new_feas+['GameId','PlayId','X','Y','S','A','Dis','Orientation','Dir',\n",
    "                                                            'YardLine','Quarter','Down','Distance','DefendersInTheBox']].drop_duplicates()\n",
    "#         static_features['DefendersInTheBox'] = static_features['DefendersInTheBox'].fillna(np.mean(static_features['DefendersInTheBox']))\n",
    "        static_features.fillna(-999,inplace=True)\n",
    "#         for i in add_new_feas:\n",
    "#             static_features[i] = static_features[i].fillna(np.mean(static_features[i]))\n",
    "            \n",
    "\n",
    "        return static_features\n",
    "\n",
    "\n",
    "    def combine_features(relative_to_back, defense, static, deploy=deploy):\n",
    "        df = pd.merge(relative_to_back,defense,on=['GameId','PlayId'],how='inner')\n",
    "        df = pd.merge(df,static,on=['GameId','PlayId'],how='inner')\n",
    "\n",
    "        if not deploy:\n",
    "            df = pd.merge(df, outcomes, on=['GameId','PlayId'], how='inner')\n",
    "\n",
    "        return df\n",
    "    \n",
    "    yardline = update_yardline(df)\n",
    "    df = update_orientation(df, yardline)\n",
    "    back_feats = back_features(df)\n",
    "    rel_back = features_relative_to_back(df, back_feats)\n",
    "    def_feats = defense_features(df)\n",
    "    static_feats = static_features(df)\n",
    "    basetable = combine_features(rel_back, def_feats, static_feats, deploy=deploy)\n",
    "    \n",
    "    return basetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:31:22.301052Z",
     "start_time": "2019-11-06T13:27:38.158256Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 59s, sys: 2.96 s, total: 4min 2s\n",
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "%time train_basetable = create_features(train, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_basetable.to_csv('/home/jupyter/Datas/NFL_Big_Data_Bowl/not_true_org_process.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_basetable.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's split our data into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:31:22.332475Z",
     "start_time": "2019-11-06T13:31:22.303336Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train_basetable.copy()\n",
    "yards = X.Yards\n",
    "\n",
    "y = np.zeros((yards.shape[0], 199))\n",
    "for idx, target in enumerate(list(yards)):\n",
    "    y[idx][99 + target] = 1\n",
    "\n",
    "X.drop(['GameId','PlayId','Yards'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:31:22.352690Z",
     "start_time": "2019-11-06T13:31:22.334326Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl = np.zeros((X.shape[0],2))\n",
    "kl[:,0] = GPClusterI(X)\n",
    "kl[:,1] = GPClusterII(X)\n",
    "ss2 = StandardScaler()\n",
    "kl = ss2.fit_transform(kl)\n",
    "X = np.concatenate([X,kl],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:31:22.372453Z",
     "start_time": "2019-11-06T13:31:22.354418Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:31:22.377333Z",
     "start_time": "2019-11-06T13:31:22.374128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19695, 34) (3476, 34)\n",
      "(19695, 199) (3476, 199)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape)\n",
    "print(y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below class Metric based entirely on: https://www.kaggle.com/kingychiu/keras-nn-starter-crps-early-stopping\n",
    "<br></br>\n",
    "Below early stopping entirely based on: https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112868#latest-656533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:31:22.386553Z",
     "start_time": "2019-11-06T13:31:22.379178Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import re\n",
    "from keras.losses import binary_crossentropy\n",
    "from  keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import codecs\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CRPSCallback(Callback):\n",
    "    \n",
    "    def __init__(self,validation, predict_batch_size=20, include_on_batch=False):\n",
    "        super(CRPSCallback, self).__init__()\n",
    "        self.validation = validation\n",
    "        self.predict_batch_size = predict_batch_size\n",
    "        self.include_on_batch = include_on_batch\n",
    "        \n",
    "        print('validation shape',len(self.validation))\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        if not ('CRPS_score_val' in self.params['metrics']):\n",
    "            self.params['metrics'].append('CRPS_score_val')\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if (self.include_on_batch):\n",
    "            logs['CRPS_score_val'] = float('-inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        logs['CRPS_score_val'] = float('-inf')\n",
    "            \n",
    "        if (self.validation):\n",
    "            X_valid, y_valid = self.validation[0], self.validation[1]\n",
    "            y_pred = self.model.predict(X_valid)\n",
    "            y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "            y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "            val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n",
    "            val_s = np.round(val_s, 6)\n",
    "            logs['CRPS_score_val'] = val_s\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:31:22.395056Z",
     "start_time": "2019-11-06T13:31:22.388490Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(x_tr,y_tr,x_val,y_val):\n",
    "    inp = Input(shape = (x_tr.shape[1],))\n",
    "    x = Dense(1024, input_dim=X.shape[1], activation='relu')(inp)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    out = Dense(199, activation='softmax')(x)\n",
    "    model = Model(inp,out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[])\n",
    "    #add lookahead\n",
    "#     lookahead = Lookahead(k=5, alpha=0.5) # Initialize Lookahead\n",
    "#     lookahead.inject(model) # add into model\n",
    "\n",
    "    \n",
    "    es = EarlyStopping(monitor='CRPS_score_val', \n",
    "                       mode='min',\n",
    "                       restore_best_weights=True, \n",
    "                       verbose=1, \n",
    "                       patience=20)\n",
    "\n",
    "    mc = ModelCheckpoint('best_model.h5',monitor='CRPS_score_val',mode='min',\n",
    "                                   save_best_only=True, verbose=1, save_weights_only=True)\n",
    "    \n",
    "    bsz = 1024\n",
    "    steps = x_tr.shape[0]/bsz\n",
    "    \n",
    "\n",
    "\n",
    "    model.fit(x_tr, y_tr,callbacks=[CRPSCallback(validation = (x_val,y_val)),es,mc], epochs=1000, batch_size=bsz,verbose=1)\n",
    "    model.load_weights(\"best_model.h5\")\n",
    "    \n",
    "    y_pred = model.predict(x_val)\n",
    "    y_valid = y_val\n",
    "    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * x_val.shape[0])\n",
    "    crps = np.round(val_s, 6)\n",
    "\n",
    "    return model,crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:37:42.061299Z",
     "start_time": "2019-11-06T13:31:22.396693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "-----------\n",
      "validation shape 2\n",
      "Epoch 1/1000\n",
      "18536/18536 [==============================] - 5s 272us/step - loss: 5.6250\n",
      "\n",
      "Epoch 00001: CRPS_score_val improved from inf to 0.08198, saving model to best_model.h5\n",
      "Epoch 2/1000\n",
      "18536/18536 [==============================] - 3s 141us/step - loss: 4.8494\n",
      "\n",
      "Epoch 00002: CRPS_score_val improved from 0.08198 to 0.06575, saving model to best_model.h5\n",
      "Epoch 3/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 4.2852\n",
      "\n",
      "Epoch 00003: CRPS_score_val improved from 0.06575 to 0.03665, saving model to best_model.h5\n",
      "Epoch 4/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 3.8118\n",
      "\n",
      "Epoch 00004: CRPS_score_val improved from 0.03665 to 0.02074, saving model to best_model.h5\n",
      "Epoch 5/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 3.4231\n",
      "\n",
      "Epoch 00005: CRPS_score_val improved from 0.02074 to 0.01533, saving model to best_model.h5\n",
      "Epoch 6/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 3.1576\n",
      "\n",
      "Epoch 00006: CRPS_score_val improved from 0.01533 to 0.01382, saving model to best_model.h5\n",
      "Epoch 7/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 3.0403\n",
      "\n",
      "Epoch 00007: CRPS_score_val improved from 0.01382 to 0.01356, saving model to best_model.h5\n",
      "Epoch 8/1000\n",
      "18536/18536 [==============================] - 3s 142us/step - loss: 2.9686\n",
      "\n",
      "Epoch 00008: CRPS_score_val improved from 0.01356 to 0.01346, saving model to best_model.h5\n",
      "Epoch 9/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.9150\n",
      "\n",
      "Epoch 00009: CRPS_score_val improved from 0.01346 to 0.01335, saving model to best_model.h5\n",
      "Epoch 10/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.8894\n",
      "\n",
      "Epoch 00010: CRPS_score_val improved from 0.01335 to 0.01329, saving model to best_model.h5\n",
      "Epoch 11/1000\n",
      "18536/18536 [==============================] - 3s 141us/step - loss: 2.8623\n",
      "\n",
      "Epoch 00011: CRPS_score_val improved from 0.01329 to 0.01328, saving model to best_model.h5\n",
      "Epoch 12/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.8411\n",
      "\n",
      "Epoch 00012: CRPS_score_val improved from 0.01328 to 0.01321, saving model to best_model.h5\n",
      "Epoch 13/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.8276\n",
      "\n",
      "Epoch 00013: CRPS_score_val improved from 0.01321 to 0.01319, saving model to best_model.h5\n",
      "Epoch 14/1000\n",
      "18536/18536 [==============================] - 3s 141us/step - loss: 2.8124\n",
      "\n",
      "Epoch 00014: CRPS_score_val improved from 0.01319 to 0.01315, saving model to best_model.h5\n",
      "Epoch 15/1000\n",
      "18536/18536 [==============================] - 3s 143us/step - loss: 2.8028\n",
      "\n",
      "Epoch 00015: CRPS_score_val improved from 0.01315 to 0.01313, saving model to best_model.h5\n",
      "Epoch 16/1000\n",
      "18536/18536 [==============================] - 3s 143us/step - loss: 2.7816\n",
      "\n",
      "Epoch 00016: CRPS_score_val improved from 0.01313 to 0.01309, saving model to best_model.h5\n",
      "Epoch 17/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.7656\n",
      "\n",
      "Epoch 00017: CRPS_score_val improved from 0.01309 to 0.01307, saving model to best_model.h5\n",
      "Epoch 18/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.7563\n",
      "\n",
      "Epoch 00018: CRPS_score_val improved from 0.01307 to 0.01305, saving model to best_model.h5\n",
      "Epoch 19/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.7449\n",
      "\n",
      "Epoch 00019: CRPS_score_val improved from 0.01305 to 0.01305, saving model to best_model.h5\n",
      "Epoch 20/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.7310\n",
      "\n",
      "Epoch 00020: CRPS_score_val improved from 0.01305 to 0.01302, saving model to best_model.h5\n",
      "Epoch 21/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.7222\n",
      "\n",
      "Epoch 00021: CRPS_score_val improved from 0.01302 to 0.01301, saving model to best_model.h5\n",
      "Epoch 22/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.7190\n",
      "\n",
      "Epoch 00022: CRPS_score_val improved from 0.01301 to 0.01300, saving model to best_model.h5\n",
      "Epoch 23/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.7025\n",
      "\n",
      "Epoch 00023: CRPS_score_val improved from 0.01300 to 0.01299, saving model to best_model.h5\n",
      "Epoch 24/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.7063\n",
      "\n",
      "Epoch 00024: CRPS_score_val improved from 0.01299 to 0.01299, saving model to best_model.h5\n",
      "Epoch 25/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.6912\n",
      "\n",
      "Epoch 00025: CRPS_score_val improved from 0.01299 to 0.01298, saving model to best_model.h5\n",
      "Epoch 26/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.6930\n",
      "\n",
      "Epoch 00026: CRPS_score_val improved from 0.01298 to 0.01295, saving model to best_model.h5\n",
      "Epoch 27/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.6789\n",
      "\n",
      "Epoch 00027: CRPS_score_val improved from 0.01295 to 0.01293, saving model to best_model.h5\n",
      "Epoch 28/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.6778\n",
      "\n",
      "Epoch 00028: CRPS_score_val improved from 0.01293 to 0.01292, saving model to best_model.h5\n",
      "Epoch 29/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.6678\n",
      "\n",
      "Epoch 00029: CRPS_score_val improved from 0.01292 to 0.01291, saving model to best_model.h5\n",
      "Epoch 30/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.6641\n",
      "\n",
      "Epoch 00030: CRPS_score_val did not improve from 0.01291\n",
      "Epoch 31/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.6632\n",
      "\n",
      "Epoch 00031: CRPS_score_val did not improve from 0.01291\n",
      "Epoch 32/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.6569\n",
      "\n",
      "Epoch 00032: CRPS_score_val did not improve from 0.01291\n",
      "Epoch 33/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.6578\n",
      "\n",
      "Epoch 00033: CRPS_score_val did not improve from 0.01291\n",
      "Epoch 34/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.6480\n",
      "\n",
      "Epoch 00034: CRPS_score_val did not improve from 0.01291\n",
      "Epoch 35/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.6401\n",
      "\n",
      "Epoch 00035: CRPS_score_val improved from 0.01291 to 0.01291, saving model to best_model.h5\n",
      "Epoch 36/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.6345\n",
      "\n",
      "Epoch 00036: CRPS_score_val did not improve from 0.01291\n",
      "Epoch 37/1000\n",
      "18536/18536 [==============================] - 3s 138us/step - loss: 2.6281\n",
      "\n",
      "Epoch 00037: CRPS_score_val improved from 0.01291 to 0.01290, saving model to best_model.h5\n",
      "Epoch 38/1000\n",
      "18536/18536 [==============================] - 3s 142us/step - loss: 2.6183\n",
      "\n",
      "Epoch 00038: CRPS_score_val did not improve from 0.01290\n",
      "Epoch 39/1000\n",
      "18536/18536 [==============================] - 3s 142us/step - loss: 2.6157\n",
      "\n",
      "Epoch 00039: CRPS_score_val did not improve from 0.01290\n",
      "Epoch 40/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.6174\n",
      "\n",
      "Epoch 00040: CRPS_score_val improved from 0.01290 to 0.01290, saving model to best_model.h5\n",
      "Epoch 41/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.6124\n",
      "\n",
      "Epoch 00041: CRPS_score_val did not improve from 0.01290\n",
      "Epoch 42/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.6140\n",
      "\n",
      "Epoch 00042: CRPS_score_val improved from 0.01290 to 0.01289, saving model to best_model.h5\n",
      "Epoch 43/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.6094\n",
      "\n",
      "Epoch 00043: CRPS_score_val did not improve from 0.01289\n",
      "Epoch 44/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.5929\n",
      "\n",
      "Epoch 00044: CRPS_score_val improved from 0.01289 to 0.01289, saving model to best_model.h5\n",
      "Epoch 45/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.5928\n",
      "\n",
      "Epoch 00045: CRPS_score_val did not improve from 0.01289\n",
      "Epoch 46/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.5916\n",
      "\n",
      "Epoch 00046: CRPS_score_val improved from 0.01289 to 0.01288, saving model to best_model.h5\n",
      "Epoch 47/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.5817\n",
      "\n",
      "Epoch 00047: CRPS_score_val did not improve from 0.01288\n",
      "Epoch 48/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.5786\n",
      "\n",
      "Epoch 00048: CRPS_score_val did not improve from 0.01288\n",
      "Epoch 49/1000\n",
      "18536/18536 [==============================] - 3s 141us/step - loss: 2.5734\n",
      "\n",
      "Epoch 00049: CRPS_score_val did not improve from 0.01288\n",
      "Epoch 50/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.5697\n",
      "\n",
      "Epoch 00050: CRPS_score_val did not improve from 0.01288\n",
      "Epoch 51/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.5733\n",
      "\n",
      "Epoch 00051: CRPS_score_val did not improve from 0.01288\n",
      "Epoch 52/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.5598\n",
      "\n",
      "Epoch 00052: CRPS_score_val improved from 0.01288 to 0.01288, saving model to best_model.h5\n",
      "Epoch 53/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.5464\n",
      "\n",
      "Epoch 00053: CRPS_score_val did not improve from 0.01288\n",
      "Epoch 54/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.5502\n",
      "\n",
      "Epoch 00054: CRPS_score_val improved from 0.01288 to 0.01287, saving model to best_model.h5\n",
      "Epoch 55/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.5385\n",
      "\n",
      "Epoch 00055: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 56/1000\n",
      "18536/18536 [==============================] - 3s 138us/step - loss: 2.5383\n",
      "\n",
      "Epoch 00056: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 57/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.5325\n",
      "\n",
      "Epoch 00057: CRPS_score_val improved from 0.01287 to 0.01287, saving model to best_model.h5\n",
      "Epoch 58/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.5317\n",
      "\n",
      "Epoch 00058: CRPS_score_val improved from 0.01287 to 0.01287, saving model to best_model.h5\n",
      "Epoch 59/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.5229\n",
      "\n",
      "Epoch 00059: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 60/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.5162\n",
      "\n",
      "Epoch 00060: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 61/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.5168\n",
      "\n",
      "Epoch 00061: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 62/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.5043\n",
      "\n",
      "Epoch 00062: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 63/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.5057\n",
      "\n",
      "Epoch 00063: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 64/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.4989\n",
      "\n",
      "Epoch 00064: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 65/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.5008\n",
      "\n",
      "Epoch 00065: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 66/1000\n",
      "18536/18536 [==============================] - 3s 141us/step - loss: 2.4930\n",
      "\n",
      "Epoch 00066: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 67/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.4852\n",
      "\n",
      "Epoch 00067: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 68/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.4797\n",
      "\n",
      "Epoch 00068: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 69/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.4722\n",
      "\n",
      "Epoch 00069: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 70/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.4690\n",
      "\n",
      "Epoch 00070: CRPS_score_val did not improve from 0.01287\n",
      "Epoch 71/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.4584\n",
      "\n",
      "Epoch 00071: CRPS_score_val improved from 0.01287 to 0.01286, saving model to best_model.h5\n",
      "Epoch 72/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.4499\n",
      "\n",
      "Epoch 00072: CRPS_score_val improved from 0.01286 to 0.01286, saving model to best_model.h5\n",
      "Epoch 73/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.4551\n",
      "\n",
      "Epoch 00073: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 74/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.4463\n",
      "\n",
      "Epoch 00074: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 75/1000\n",
      "18536/18536 [==============================] - 3s 141us/step - loss: 2.4337\n",
      "\n",
      "Epoch 00075: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 76/1000\n",
      "18536/18536 [==============================] - 3s 138us/step - loss: 2.4278\n",
      "\n",
      "Epoch 00076: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 77/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.4268\n",
      "\n",
      "Epoch 00077: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 78/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.4108\n",
      "\n",
      "Epoch 00078: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 79/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.4069\n",
      "\n",
      "Epoch 00079: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 80/1000\n",
      "18536/18536 [==============================] - 3s 141us/step - loss: 2.3993\n",
      "\n",
      "Epoch 00080: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 81/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.3977\n",
      "\n",
      "Epoch 00081: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 82/1000\n",
      "18536/18536 [==============================] - 3s 142us/step - loss: 2.3926\n",
      "\n",
      "Epoch 00082: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 83/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.3867\n",
      "\n",
      "Epoch 00083: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 84/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.3866\n",
      "\n",
      "Epoch 00084: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 85/1000\n",
      "18536/18536 [==============================] - 3s 138us/step - loss: 2.3792\n",
      "\n",
      "Epoch 00085: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 86/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.3656\n",
      "\n",
      "Epoch 00086: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 87/1000\n",
      "18536/18536 [==============================] - 3s 138us/step - loss: 2.3574\n",
      "\n",
      "Epoch 00087: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 88/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.3561\n",
      "\n",
      "Epoch 00088: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 89/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.3493\n",
      "\n",
      "Epoch 00089: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 90/1000\n",
      "18536/18536 [==============================] - 3s 140us/step - loss: 2.3448\n",
      "\n",
      "Epoch 00090: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 91/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.3426\n",
      "\n",
      "Epoch 00091: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 92/1000\n",
      "18536/18536 [==============================] - 3s 139us/step - loss: 2.3332\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00092: CRPS_score_val did not improve from 0.01286\n",
      "Epoch 00092: early stopping\n",
      "the 1 fold crps is 0.012859\n",
      "-----------\n",
      "-----------\n",
      "validation shape 2\n",
      "Epoch 1/1000\n",
      "18537/18537 [==============================] - 3s 182us/step - loss: 5.6221\n",
      "\n",
      "Epoch 00001: CRPS_score_val improved from inf to 0.08151, saving model to best_model.h5\n",
      "Epoch 2/1000\n",
      "18537/18537 [==============================] - 3s 138us/step - loss: 4.8691\n",
      "\n",
      "Epoch 00002: CRPS_score_val improved from 0.08151 to 0.06540, saving model to best_model.h5\n",
      "Epoch 3/1000\n",
      "18537/18537 [==============================] - 3s 139us/step - loss: 4.3014\n",
      "\n",
      "Epoch 00003: CRPS_score_val improved from 0.06540 to 0.03791, saving model to best_model.h5\n",
      "Epoch 4/1000\n",
      "18537/18537 [==============================] - 3s 139us/step - loss: 3.8200\n",
      "\n",
      "Epoch 00004: CRPS_score_val improved from 0.03791 to 0.02053, saving model to best_model.h5\n",
      "Epoch 5/1000\n",
      "18537/18537 [==============================] - 3s 140us/step - loss: 3.4244\n",
      "\n",
      "Epoch 00005: CRPS_score_val improved from 0.02053 to 0.01512, saving model to best_model.h5\n",
      "Epoch 6/1000\n",
      "18537/18537 [==============================] - 3s 139us/step - loss: 3.1415\n",
      "\n",
      "Epoch 00006: CRPS_score_val improved from 0.01512 to 0.01381, saving model to best_model.h5\n",
      "Epoch 7/1000\n",
      "18537/18537 [==============================] - 3s 140us/step - loss: 3.0105\n",
      "\n",
      "Epoch 00007: CRPS_score_val improved from 0.01381 to 0.01342, saving model to best_model.h5\n",
      "Epoch 8/1000\n",
      "18537/18537 [==============================] - 3s 140us/step - loss: 2.9529\n",
      "\n",
      "Epoch 00008: CRPS_score_val improved from 0.01342 to 0.01335, saving model to best_model.h5\n",
      "Epoch 9/1000\n",
      "18537/18537 [==============================] - 3s 139us/step - loss: 2.9166\n",
      "\n",
      "Epoch 00009: CRPS_score_val improved from 0.01335 to 0.01328, saving model to best_model.h5\n",
      "Epoch 10/1000\n",
      "18537/18537 [==============================] - 3s 139us/step - loss: 2.8731\n",
      "\n",
      "Epoch 00010: CRPS_score_val improved from 0.01328 to 0.01318, saving model to best_model.h5\n",
      "Epoch 11/1000\n",
      "18537/18537 [==============================] - 3s 140us/step - loss: 2.8542\n",
      "\n",
      "Epoch 00011: CRPS_score_val improved from 0.01318 to 0.01314, saving model to best_model.h5\n",
      "Epoch 12/1000\n",
      "18537/18537 [==============================] - 3s 139us/step - loss: 2.8317\n",
      "\n",
      "Epoch 00012: CRPS_score_val improved from 0.01314 to 0.01311, saving model to best_model.h5\n",
      "Epoch 13/1000\n",
      "18537/18537 [==============================] - 3s 140us/step - loss: 2.8079\n",
      "\n",
      "Epoch 00013: CRPS_score_val improved from 0.01311 to 0.01304, saving model to best_model.h5\n",
      "Epoch 14/1000\n",
      "18537/18537 [==============================] - 3s 139us/step - loss: 2.7930\n",
      "\n",
      "Epoch 00014: CRPS_score_val did not improve from 0.01304\n",
      "Epoch 15/1000\n",
      "18537/18537 [==============================] - 3s 140us/step - loss: 2.7758\n",
      "\n",
      "Epoch 00015: CRPS_score_val improved from 0.01304 to 0.01302, saving model to best_model.h5\n",
      "Epoch 16/1000\n",
      "18537/18537 [==============================] - 3s 140us/step - loss: 2.7730\n",
      "\n",
      "Epoch 00016: CRPS_score_val improved from 0.01302 to 0.01300, saving model to best_model.h5\n",
      "Epoch 17/1000\n",
      "18537/18537 [==============================] - 3s 142us/step - loss: 2.7548\n",
      "\n",
      "Epoch 00017: CRPS_score_val improved from 0.01300 to 0.01296, saving model to best_model.h5\n",
      "Epoch 18/1000\n",
      "18537/18537 [==============================] - 3s 140us/step - loss: 2.7375\n",
      "\n",
      "Epoch 00018: CRPS_score_val improved from 0.01296 to 0.01293, saving model to best_model.h5\n",
      "Epoch 19/1000\n",
      "18537/18537 [==============================] - 3s 141us/step - loss: 2.7359\n",
      "\n",
      "Epoch 00019: CRPS_score_val did not improve from 0.01293\n",
      "Epoch 20/1000\n",
      "18537/18537 [==============================] - 3s 139us/step - loss: 2.7247\n",
      "\n",
      "Epoch 00020: CRPS_score_val improved from 0.01293 to 0.01292, saving model to best_model.h5\n",
      "Epoch 21/1000\n",
      " 7168/18537 [==========>...................] - ETA: 1s - loss: 2.7156"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import time\n",
    "\n",
    "losses = []\n",
    "models = []\n",
    "crps_csv = []\n",
    "\n",
    "s_time = time.time()\n",
    "\n",
    "\n",
    "for k in range(2):\n",
    "    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n",
    "    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n",
    "        print(\"-----------\")\n",
    "        print(\"-----------\")\n",
    "        tr_x,tr_y = X[tr_inds],y[tr_inds]\n",
    "        val_x,val_y = X[val_inds],y[val_inds]\n",
    "        model,crps = get_model(tr_x,tr_y,val_x,val_y)\n",
    "        models.append(model)\n",
    "        print(\"the %d fold crps is %f\"%((k_fold+1),crps))\n",
    "        crps_csv.append(crps)\n",
    " \n",
    "print(\"mean crps is %f\"%np.mean(crps_csv))\n",
    "\n",
    "\n",
    "def predict(x_te):\n",
    "    model_num = len(models)\n",
    "    for k,m in enumerate(models):\n",
    "        if k==0:\n",
    "            y_pred = m.predict(x_te,batch_size=1024)\n",
    "        else:\n",
    "            y_pred+=m.predict(x_te,batch_size=1024)\n",
    "            \n",
    "    y_pred = y_pred / model_num\n",
    "    \n",
    "    return y_pred\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:37:42.068378Z",
     "start_time": "2019-11-06T13:37:42.063981Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"mean crps is %f\"%np.mean(crps_csv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time for the actual submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T13:37:42.077763Z",
     "start_time": "2019-11-06T13:37:42.070691Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if  TRAIN_OFFLINE==False:\n",
    "    from kaggle.competitions import nflrush\n",
    "    env = nflrush.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "\n",
    "    for (test_df, sample_prediction_df) in iter_test:\n",
    "        basetable = create_features(test_df, deploy=True)\n",
    "        basetable.drop(['GameId','PlayId'], axis=1, inplace=True)\n",
    "        scaled_basetable = scaler.transform(basetable)\n",
    "        kl = np.zeros((scaled_basetable.shape[0],2))\n",
    "        kl[:,0] = GPClusterI(scaled_basetable)\n",
    "        kl[:,1] = GPClusterII(scaled_basetable)\n",
    "        kl = ss2.transform(kl)\n",
    "        scaled_basetable = np.concatenate([scaled_basetable,kl],axis=1)\n",
    "        y_pred = predict(scaled_basetable)\n",
    "        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1).tolist()[0]\n",
    "\n",
    "        preds_df = pd.DataFrame(data=[y_pred], columns=sample_prediction_df.columns)\n",
    "        env.predict(preds_df)\n",
    "\n",
    "    env.write_submission_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
